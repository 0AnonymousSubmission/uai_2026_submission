{
  "experiment_name": "kfold_obesity",
  "run_name": "obesity-BTT-L3-d6-seed42806-fold0",
  "config": {
    "params": {
      "model": "BTT",
      "L": 3,
      "bond_dim": 6,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 0,
    "seed": 42806
  },
  "hparams": {
    "seed": 42806,
    "fold": 0,
    "dataset": "obesity",
    "n_features": 40,
    "n_train": 1435,
    "n_val": 253,
    "n_test": 423,
    "L": 3,
    "bond_dim": 6,
    "model": "BTT",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 2.30965698695372,
      "train_quality": 0.3967890739315847,
      "val_loss": 2.5463718870915795,
      "val_quality": 0.2996695020029525,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 1.0996386790183603,
      "train_quality": 0.7128084084961118,
      "val_loss": 1.3888271954924307,
      "val_quality": 0.6180298540124135,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 0.8973994208712296,
      "train_quality": 0.7656270438533994,
      "val_loss": 1.1006857841703845,
      "val_quality": 0.6972775943396232,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 0.8204605643713941,
      "train_quality": 0.7857210920787694,
      "val_loss": 1.071896399109827,
      "val_quality": 0.7051955596920911,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 0.7729490809694664,
      "train_quality": 0.7981296211649697,
      "val_loss": 1.0645211335110343,
      "val_quality": 0.7072239843129591,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 0.7497802751705828,
      "train_quality": 0.8041805962148522,
      "val_loss": 1.0587897006672078,
      "val_quality": 0.7088003044247627,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 0.733904999082814,
      "train_quality": 0.8083267270232737,
      "val_loss": 1.0512052333119393,
      "val_quality": 0.7108862659557096,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 0.7201287869021576,
      "train_quality": 0.8119246473006777,
      "val_loss": 1.0443089601578734,
      "val_quality": 0.7127829529387829,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 0.7076303467978476,
      "train_quality": 0.8151888530560418,
      "val_loss": 1.036794982530743,
      "val_quality": 0.7148495276289226,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 0.6962375556602658,
      "train_quality": 0.8181642975187579,
      "val_loss": 1.026069533250614,
      "val_quality": 0.7177993556857247,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 0.6860079058717383,
      "train_quality": 0.8208359654578279,
      "val_loss": 1.0121628532633944,
      "val_quality": 0.7216241199200091,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 0.6769748345525801,
      "train_quality": 0.8231951241322326,
      "val_loss": 0.9959183756844903,
      "val_quality": 0.7260918503132825,
      "patience_counter": 0
    },
    {
      "step": 13,
      "train_loss": 0.6690175124020162,
      "train_quality": 0.8252733304159272,
      "val_loss": 0.9784779879427116,
      "val_quality": 0.7308884927418211,
      "patience_counter": 0
    },
    {
      "step": 14,
      "train_loss": 0.6619219786568068,
      "train_quality": 0.8271264642386438,
      "val_loss": 0.9612437219116401,
      "val_quality": 0.735628445367492,
      "patience_counter": 0
    },
    {
      "step": 15,
      "train_loss": 0.6555265720947704,
      "train_quality": 0.8287967465085484,
      "val_loss": 0.9454633231932589,
      "val_quality": 0.7399685398167982,
      "patience_counter": 0
    },
    {
      "step": 16,
      "train_loss": 0.6498416599833565,
      "train_quality": 0.8302814696162277,
      "val_loss": 0.9321759160433601,
      "val_quality": 0.7436229849956628,
      "patience_counter": 0
    },
    {
      "step": 17,
      "train_loss": 0.6449678370507919,
      "train_quality": 0.8315543613318601,
      "val_loss": 0.9222292113940245,
      "val_quality": 0.7463586343545847,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 0.6409205561942688,
      "train_quality": 0.8326113858369328,
      "val_loss": 0.9159523083605424,
      "val_quality": 0.7480849755263522,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 0.637582168280605,
      "train_quality": 0.8334832694440448,
      "val_loss": 0.9130365951640255,
      "val_quality": 0.7488868862312594,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 0.6347666255573599,
      "train_quality": 0.8342186020683554,
      "val_loss": 0.9128219402295636,
      "val_quality": 0.7489459229328155,
      "patience_counter": 1
    },
    {
      "step": 21,
      "train_loss": 0.6322899175574688,
      "train_quality": 0.8348654415491329,
      "val_loss": 0.9146299441030186,
      "val_quality": 0.7484486663225395,
      "patience_counter": 2
    },
    {
      "step": 22,
      "train_loss": 0.6300038994721768,
      "train_quality": 0.8354624787256605,
      "val_loss": 0.9179305263941246,
      "val_quality": 0.7475409047927613,
      "patience_counter": 3
    },
    {
      "step": 23,
      "train_loss": 0.6278015276602307,
      "train_quality": 0.8360376700842627,
      "val_loss": 0.9223680501008573,
      "val_quality": 0.746320449444835,
      "patience_counter": 4
    },
    {
      "step": 24,
      "train_loss": 0.625611006183192,
      "train_quality": 0.8366097665021295,
      "val_loss": 0.9277271152736252,
      "val_quality": 0.744846541882366,
      "patience_counter": 5
    },
    {
      "step": 25,
      "train_loss": 0.6233888515923539,
      "train_quality": 0.8371901245103438,
      "val_loss": 0.9338868125380184,
      "val_quality": 0.7431524358978663,
      "patience_counter": 6
    },
    {
      "step": 26,
      "train_loss": 0.621114804744588,
      "train_quality": 0.8377840351701137,
      "val_loss": 0.9407793927853366,
      "val_quality": 0.7412567645776011,
      "patience_counter": 7
    },
    {
      "step": 27,
      "train_loss": 0.6187884261634041,
      "train_quality": 0.8383916132590976,
      "val_loss": 0.9483547851308451,
      "val_quality": 0.7391732989531385,
      "patience_counter": 8
    },
    {
      "step": 28,
      "train_loss": 0.6164262388439822,
      "train_quality": 0.8390085434823057,
      "val_loss": 0.9565508104630756,
      "val_quality": 0.7369191401903847,
      "patience_counter": 9
    },
    {
      "step": 29,
      "train_loss": 0.6140580928217394,
      "train_quality": 0.8396270299342816,
      "val_loss": 0.965271962326835,
      "val_quality": 0.734520555498645,
      "patience_counter": 10
    },
    {
      "step": 30,
      "train_loss": 0.6117218236781383,
      "train_quality": 0.8402371911320772,
      "val_loss": 0.9743817479834664,
      "val_quality": 0.732015084574348,
      "patience_counter": 11
    },
    {
      "step": 31,
      "train_loss": 0.6094563158625619,
      "train_quality": 0.8408288716609039,
      "val_loss": 0.9837118100722348,
      "val_quality": 0.729449030863932,
      "patience_counter": 12
    },
    {
      "step": 32,
      "train_loss": 0.6072943619592652,
      "train_quality": 0.8413935071126144,
      "val_loss": 0.9930852549800108,
      "val_quality": 0.7268710455454919,
      "patience_counter": 13
    },
    {
      "step": 33,
      "train_loss": 0.6052573435052505,
      "train_quality": 0.8419255132914563,
      "val_loss": 1.0023452983699297,
      "val_quality": 0.7243242491283577,
      "patience_counter": 14
    },
    {
      "step": 34,
      "train_loss": 0.6033531380065282,
      "train_quality": 0.8424228328366514,
      "val_loss": 1.0113784003945474,
      "val_quality": 0.7218398685587213,
      "patience_counter": 15
    },
    {
      "step": 35,
      "train_loss": 0.6015772022023536,
      "train_quality": 0.8428866523073024,
      "val_loss": 1.0201250696681754,
      "val_quality": 0.7194342657953277,
      "patience_counter": 16
    },
    {
      "step": 36,
      "train_loss": 0.5999155949039382,
      "train_quality": 0.8433206127104709,
      "val_loss": 1.0285780425407882,
      "val_quality": 0.717109438565086,
      "patience_counter": 17
    },
    {
      "step": 37,
      "train_loss": 0.598348464445631,
      "train_quality": 0.8437298986868584,
      "val_loss": 1.0367719694563868,
      "val_quality": 0.714855856931373,
      "patience_counter": 18
    },
    {
      "step": 38,
      "train_loss": 0.5968530317895141,
      "train_quality": 0.8441204594162067,
      "val_loss": 1.0447694633123428,
      "val_quality": 0.7126563004238327,
      "patience_counter": 19
    },
    {
      "step": 39,
      "train_loss": 0.5954057599287692,
      "train_quality": 0.8444984420362771,
      "val_loss": 1.0526468491908128,
      "val_quality": 0.7104897773000305,
      "patience_counter": 20
    }
  ],
  "summary": {
    "test_quality": 0.6975557132524992,
    "test_loss": 1.1528646334522965,
    "best_val_quality": 0.7488868862312594,
    "n_parameters": 972
  }
}