{
  "experiment_name": "kfold_obesity",
  "run_name": "obesity-BTT-L3-d6-seed42-fold0",
  "config": {
    "params": {
      "model": "BTT",
      "L": 3,
      "bond_dim": 6,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 0,
    "seed": 42
  },
  "hparams": {
    "seed": 42,
    "fold": 0,
    "dataset": "obesity",
    "n_features": 40,
    "n_train": 1435,
    "n_val": 253,
    "n_test": 423,
    "L": 3,
    "bond_dim": 6,
    "model": "BTT",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 2.424225451618057,
      "train_quality": 0.3703365912518871,
      "val_loss": 3.0448582214010713,
      "val_quality": 0.17547327184798278,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 1.3433749293893913,
      "train_quality": 0.6510745167280138,
      "val_loss": 1.9039906851650332,
      "val_quality": 0.4844123778779206,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 0.9841032495433467,
      "train_quality": 0.7443910151780774,
      "val_loss": 1.592050270131662,
      "val_quality": 0.5688837033334282,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 0.8417625816990377,
      "train_quality": 0.7813622919454708,
      "val_loss": 1.4295437303350018,
      "val_quality": 0.6128893600238047,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 0.7865175939951775,
      "train_quality": 0.7957115131578141,
      "val_loss": 1.3964545344939798,
      "val_quality": 0.6218496873691697,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 0.7541193775773265,
      "train_quality": 0.8041265602704525,
      "val_loss": 1.3941905761652427,
      "val_quality": 0.6224627517609189,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 0.7282523525227478,
      "train_quality": 0.8108452089667475,
      "val_loss": 1.410160166445174,
      "val_quality": 0.6181382962145516,
      "patience_counter": 1
    },
    {
      "step": 8,
      "train_loss": 0.7069936367012288,
      "train_quality": 0.816366904756572,
      "val_loss": 1.4356035390980526,
      "val_quality": 0.6112484053621042,
      "patience_counter": 2
    },
    {
      "step": 9,
      "train_loss": 0.6904045988890037,
      "train_quality": 0.8206757078382843,
      "val_loss": 1.4573399712703665,
      "val_quality": 0.6053623285737769,
      "patience_counter": 3
    },
    {
      "step": 10,
      "train_loss": 0.6779230781137265,
      "train_quality": 0.8239176327642337,
      "val_loss": 1.471960803052425,
      "val_quality": 0.6014031075803691,
      "patience_counter": 4
    },
    {
      "step": 11,
      "train_loss": 0.6685373516434192,
      "train_quality": 0.8263554623476689,
      "val_loss": 1.4767988809775683,
      "val_quality": 0.6000929892523218,
      "patience_counter": 5
    },
    {
      "step": 12,
      "train_loss": 0.6614301379588199,
      "train_quality": 0.8282014756350713,
      "val_loss": 1.4718011234865458,
      "val_quality": 0.6014463477119067,
      "patience_counter": 6
    },
    {
      "step": 13,
      "train_loss": 0.6559507183178888,
      "train_quality": 0.8296246889945248,
      "val_loss": 1.459360447267349,
      "val_quality": 0.6048151975279397,
      "patience_counter": 7
    },
    {
      "step": 14,
      "train_loss": 0.6516016266990197,
      "train_quality": 0.8307543132429078,
      "val_loss": 1.4426120149980635,
      "val_quality": 0.6093505581446041,
      "patience_counter": 8
    },
    {
      "step": 15,
      "train_loss": 0.6480644077955859,
      "train_quality": 0.8316730633165603,
      "val_loss": 1.4238876095119963,
      "val_quality": 0.6144209987593775,
      "patience_counter": 9
    },
    {
      "step": 16,
      "train_loss": 0.645143624720724,
      "train_quality": 0.832431701596636,
      "val_loss": 1.404692879467602,
      "val_quality": 0.6196188000395906,
      "patience_counter": 10
    },
    {
      "step": 17,
      "train_loss": 0.6427004814624353,
      "train_quality": 0.8330662786781724,
      "val_loss": 1.3859992020729632,
      "val_quality": 0.6246809196979037,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 0.640619959787469,
      "train_quality": 0.8336066691641147,
      "val_loss": 1.3683847687801933,
      "val_quality": 0.6294507874536696,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 0.6388075627452817,
      "train_quality": 0.8340774175010018,
      "val_loss": 1.3521791166102315,
      "val_quality": 0.6338391669412109,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 0.6371894137364973,
      "train_quality": 0.8344977122471252,
      "val_loss": 1.3375741599041255,
      "val_quality": 0.6377940890729042,
      "patience_counter": 0
    },
    {
      "step": 21,
      "train_loss": 0.6357077993256876,
      "train_quality": 0.8348825437733094,
      "val_loss": 1.3246500318097258,
      "val_quality": 0.6412938543417743,
      "patience_counter": 0
    },
    {
      "step": 22,
      "train_loss": 0.6343168187718131,
      "train_quality": 0.8352438342450641,
      "val_loss": 1.3133820961011309,
      "val_quality": 0.6443451340688678,
      "patience_counter": 0
    },
    {
      "step": 23,
      "train_loss": 0.6329801292348171,
      "train_quality": 0.8355910232780566,
      "val_loss": 1.3036585624305443,
      "val_quality": 0.6469782003138359,
      "patience_counter": 0
    },
    {
      "step": 24,
      "train_loss": 0.6316704977728074,
      "train_quality": 0.8359311843014557,
      "val_loss": 1.29529697253012,
      "val_quality": 0.6492424615245183,
      "patience_counter": 0
    },
    {
      "step": 25,
      "train_loss": 0.630370704484499,
      "train_quality": 0.8362687899775442,
      "val_loss": 1.2880549135483452,
      "val_quality": 0.6512035614389107,
      "patience_counter": 0
    },
    {
      "step": 26,
      "train_loss": 0.6290748934711252,
      "train_quality": 0.8366053613056068,
      "val_loss": 1.2816410052397678,
      "val_quality": 0.6529404038295246,
      "patience_counter": 0
    },
    {
      "step": 27,
      "train_loss": 0.6277885919792394,
      "train_quality": 0.8369394626498188,
      "val_loss": 1.275733202778385,
      "val_quality": 0.6545401962270212,
      "patience_counter": 0
    },
    {
      "step": 28,
      "train_loss": 0.6265255368002828,
      "train_quality": 0.837267526043794,
      "val_loss": 1.2700073542528223,
      "val_quality": 0.6560907167463325,
      "patience_counter": 0
    },
    {
      "step": 29,
      "train_loss": 0.6253009889463234,
      "train_quality": 0.8375855876231675,
      "val_loss": 1.264175604994757,
      "val_quality": 0.6576699144578577,
      "patience_counter": 0
    },
    {
      "step": 30,
      "train_loss": 0.624123945427549,
      "train_quality": 0.837891310522736,
      "val_loss": 1.2580317374467438,
      "val_quality": 0.6593336316621458,
      "patience_counter": 0
    },
    {
      "step": 31,
      "train_loss": 0.6229928780010643,
      "train_quality": 0.8381850916852137,
      "val_loss": 1.251491893302055,
      "val_quality": 0.6611045766136526,
      "patience_counter": 0
    },
    {
      "step": 32,
      "train_loss": 0.6218982359085712,
      "train_quality": 0.8384694118052167,
      "val_loss": 1.2446072636638255,
      "val_quality": 0.6629688871126602,
      "patience_counter": 0
    },
    {
      "step": 33,
      "train_loss": 0.6208297147649106,
      "train_quality": 0.8387469473228756,
      "val_loss": 1.2375336644443615,
      "val_quality": 0.664884369278526,
      "patience_counter": 0
    },
    {
      "step": 34,
      "train_loss": 0.6197828429270217,
      "train_quality": 0.8390188596937022,
      "val_loss": 1.2304771783843984,
      "val_quality": 0.6667952173181415,
      "patience_counter": 0
    },
    {
      "step": 35,
      "train_loss": 0.6187611224565419,
      "train_quality": 0.8392842392992997,
      "val_loss": 1.223651506416249,
      "val_quality": 0.6686435624843567,
      "patience_counter": 0
    },
    {
      "step": 36,
      "train_loss": 0.6177737331555467,
      "train_quality": 0.8395407017964701,
      "val_loss": 1.2172591091405685,
      "val_quality": 0.6703745798347605,
      "patience_counter": 0
    },
    {
      "step": 37,
      "train_loss": 0.6168311219189981,
      "train_quality": 0.8397855337298752,
      "val_loss": 1.211482476157162,
      "val_quality": 0.6719388524370333,
      "patience_counter": 0
    },
    {
      "step": 38,
      "train_loss": 0.6159409870204312,
      "train_quality": 0.8400167355655391,
      "val_loss": 1.2064720904489823,
      "val_quality": 0.6732956305312345,
      "patience_counter": 0
    },
    {
      "step": 39,
      "train_loss": 0.6151060915004054,
      "train_quality": 0.8402335896369033,
      "val_loss": 1.2023316571534892,
      "val_quality": 0.6744168314772324,
      "patience_counter": 0
    },
    {
      "step": 40,
      "train_loss": 0.6143240616801521,
      "train_quality": 0.8404367124784834,
      "val_loss": 1.1991091071794704,
      "val_quality": 0.6752894759135837,
      "patience_counter": 0
    },
    {
      "step": 41,
      "train_loss": 0.6135885573111991,
      "train_quality": 0.8406277508935759,
      "val_loss": 1.1967989674670676,
      "val_quality": 0.67591504590737,
      "patience_counter": 0
    },
    {
      "step": 42,
      "train_loss": 0.6128910244413506,
      "train_quality": 0.8408089266683989,
      "val_loss": 1.195354571504706,
      "val_quality": 0.676306178429939,
      "patience_counter": 0
    },
    {
      "step": 43,
      "train_loss": 0.6122223945315739,
      "train_quality": 0.8409825952469133,
      "val_loss": 1.194704232904088,
      "val_quality": 0.6764822856636978,
      "patience_counter": 0
    },
    {
      "step": 44,
      "train_loss": 0.6115743549908819,
      "train_quality": 0.8411509157246657,
      "val_loss": 1.1947656726976188,
      "val_quality": 0.6764656481888944,
      "patience_counter": 1
    },
    {
      "step": 45,
      "train_loss": 0.6109400758775705,
      "train_quality": 0.8413156620968807,
      "val_loss": 1.1954556452000331,
      "val_quality": 0.6762788083662938,
      "patience_counter": 2
    },
    {
      "step": 46,
      "train_loss": 0.6103144641702671,
      "train_quality": 0.8414781572146143,
      "val_loss": 1.1966944395061254,
      "val_quality": 0.6759433513624582,
      "patience_counter": 3
    },
    {
      "step": 47,
      "train_loss": 0.6096941000428263,
      "train_quality": 0.8416392893365828,
      "val_loss": 1.1984066034482346,
      "val_quality": 0.6754797091070242,
      "patience_counter": 4
    },
    {
      "step": 48,
      "train_loss": 0.6090770076052543,
      "train_quality": 0.8417995716764514,
      "val_loss": 1.2005197787081558,
      "val_quality": 0.67490747573641,
      "patience_counter": 5
    },
    {
      "step": 49,
      "train_loss": 0.6084623685487779,
      "train_quality": 0.8419592167800833,
      "val_loss": 1.2029632952072755,
      "val_quality": 0.6742457882233285,
      "patience_counter": 6
    },
    {
      "step": 50,
      "train_loss": 0.6078502381337456,
      "train_quality": 0.8421182102942675,
      "val_loss": 1.2056675341906258,
      "val_quality": 0.673513498849258,
      "patience_counter": 7
    }
  ],
  "summary": {
    "test_quality": 0.6979992912734732,
    "test_loss": 1.1153412825077471,
    "best_val_quality": 0.6764822856636978,
    "n_parameters": 972
  }
}