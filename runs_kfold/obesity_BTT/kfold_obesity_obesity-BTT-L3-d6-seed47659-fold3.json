{
  "experiment_name": "kfold_obesity",
  "run_name": "obesity-BTT-L3-d6-seed47659-fold3",
  "config": {
    "params": {
      "model": "BTT",
      "L": 3,
      "bond_dim": 6,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 3,
    "seed": 47659
  },
  "hparams": {
    "seed": 47659,
    "fold": 3,
    "dataset": "obesity",
    "n_features": 40,
    "n_train": 1436,
    "n_val": 253,
    "n_test": 422,
    "L": 3,
    "bond_dim": 6,
    "model": "BTT",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 2.4927079745142064,
      "train_quality": 0.3437976270906088,
      "val_loss": 3.108188116967427,
      "val_quality": 0.14308351920572637,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 1.4872690436177078,
      "train_quality": 0.6084782150356705,
      "val_loss": 2.201750310411753,
      "val_quality": 0.39298521949612386,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 1.16553378224219,
      "train_quality": 0.693174635202731,
      "val_loss": 1.8180571705668844,
      "val_quality": 0.4987680623381987,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 1.0368556029165419,
      "train_quality": 0.7270490109733652,
      "val_loss": 1.6844708267519326,
      "val_quality": 0.5355973452889906,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 0.9767239225700228,
      "train_quality": 0.7428786034221576,
      "val_loss": 1.6444212809342262,
      "val_quality": 0.546638863552371,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 0.9273500041132536,
      "train_quality": 0.7558762280065139,
      "val_loss": 1.6106188939842214,
      "val_quality": 0.5559580621908065,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 0.8789945228748394,
      "train_quality": 0.7686057502194024,
      "val_loss": 1.5621715062733001,
      "val_quality": 0.56931483578964,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 0.8389191564804306,
      "train_quality": 0.7791555421693999,
      "val_loss": 1.5088705520975227,
      "val_quality": 0.584009720512334,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 0.8125887595672429,
      "train_quality": 0.7860869874532972,
      "val_loss": 1.4653482093382966,
      "val_quality": 0.5960086766210608,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 0.7939745631650912,
      "train_quality": 0.7909871522434684,
      "val_loss": 1.4458761947773324,
      "val_quality": 0.601377042229458,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 0.7777470844473667,
      "train_quality": 0.7952590164769764,
      "val_loss": 1.433393167270967,
      "val_quality": 0.604818568803097,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 0.7631686916775444,
      "train_quality": 0.7990967608203052,
      "val_loss": 1.4236505369013426,
      "val_quality": 0.6075045775695689,
      "patience_counter": 0
    },
    {
      "step": 13,
      "train_loss": 0.751358447117096,
      "train_quality": 0.8022057934805457,
      "val_loss": 1.4149905036162456,
      "val_quality": 0.6098921181452877,
      "patience_counter": 0
    },
    {
      "step": 14,
      "train_loss": 0.7418147750605464,
      "train_quality": 0.8047181536582345,
      "val_loss": 1.40141153280711,
      "val_quality": 0.6136357924148892,
      "patience_counter": 0
    },
    {
      "step": 15,
      "train_loss": 0.7327768933838559,
      "train_quality": 0.8070973651274297,
      "val_loss": 1.3877710821892884,
      "val_quality": 0.6173964164505015,
      "patience_counter": 0
    },
    {
      "step": 16,
      "train_loss": 0.7235316175573713,
      "train_quality": 0.8095311728568423,
      "val_loss": 1.3826214524215439,
      "val_quality": 0.6188161511808029,
      "patience_counter": 0
    },
    {
      "step": 17,
      "train_loss": 0.7154023394773737,
      "train_quality": 0.8116711955232255,
      "val_loss": 1.3808669470714847,
      "val_quality": 0.6192998621061165,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 0.7087375840203233,
      "train_quality": 0.8134256843724978,
      "val_loss": 1.3760386261179387,
      "val_quality": 0.6206310131317163,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 0.703138278907424,
      "train_quality": 0.8148996947015434,
      "val_loss": 1.3705812443786083,
      "val_quality": 0.6221355939931157,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 0.6983240411345675,
      "train_quality": 0.8161670369985945,
      "val_loss": 1.3681913234747245,
      "val_quality": 0.6227944867413225,
      "patience_counter": 0
    },
    {
      "step": 21,
      "train_loss": 0.6940466332077464,
      "train_quality": 0.8172930594850547,
      "val_loss": 1.3706365399359455,
      "val_quality": 0.6221203492033494,
      "patience_counter": 1
    },
    {
      "step": 22,
      "train_loss": 0.6900746930781624,
      "train_quality": 0.8183386679416951,
      "val_loss": 1.3784508617197582,
      "val_quality": 0.6199659683001395,
      "patience_counter": 2
    },
    {
      "step": 23,
      "train_loss": 0.686217964887187,
      "train_quality": 0.8193539469942194,
      "val_loss": 1.3917026736861091,
      "val_quality": 0.6163124905674492,
      "patience_counter": 3
    },
    {
      "step": 24,
      "train_loss": 0.6823207436523794,
      "train_quality": 0.8203798857917763,
      "val_loss": 1.41010319017157,
      "val_quality": 0.6112395331922367,
      "patience_counter": 4
    },
    {
      "step": 25,
      "train_loss": 0.6782545363037776,
      "train_quality": 0.8214503099803193,
      "val_loss": 1.4330195624200273,
      "val_quality": 0.6049215703403359,
      "patience_counter": 5
    },
    {
      "step": 26,
      "train_loss": 0.6739334091201011,
      "train_quality": 0.8225878415085057,
      "val_loss": 1.4596371863729796,
      "val_quality": 0.5975831854722014,
      "patience_counter": 6
    },
    {
      "step": 27,
      "train_loss": 0.6693576240753925,
      "train_quality": 0.8237924114119844,
      "val_loss": 1.4891394581598094,
      "val_quality": 0.5894495133894213,
      "patience_counter": 7
    },
    {
      "step": 28,
      "train_loss": 0.6646670571529505,
      "train_quality": 0.8250271975065717,
      "val_loss": 1.5205807358776866,
      "val_quality": 0.5807812642230981,
      "patience_counter": 8
    },
    {
      "step": 29,
      "train_loss": 0.6601374789467644,
      "train_quality": 0.8262196035154452,
      "val_loss": 1.5524001844775215,
      "val_quality": 0.5720087546809188,
      "patience_counter": 9
    },
    {
      "step": 30,
      "train_loss": 0.6560534788994787,
      "train_quality": 0.8272947116104933,
      "val_loss": 1.5823338542505148,
      "val_quality": 0.563756147697736,
      "patience_counter": 10
    },
    {
      "step": 31,
      "train_loss": 0.6525534475991617,
      "train_quality": 0.8282160906360378,
      "val_loss": 1.6084233996895452,
      "val_quality": 0.5565633522098783,
      "patience_counter": 11
    },
    {
      "step": 32,
      "train_loss": 0.6496124995460515,
      "train_quality": 0.8289902916699277,
      "val_loss": 1.630053429228947,
      "val_quality": 0.55060002949746,
      "patience_counter": 12
    },
    {
      "step": 33,
      "train_loss": 0.6471252760481668,
      "train_quality": 0.829645050260968,
      "val_loss": 1.647824911103521,
      "val_quality": 0.5457004947417203,
      "patience_counter": 13
    },
    {
      "step": 34,
      "train_loss": 0.6449757864271078,
      "train_quality": 0.8302109008155873,
      "val_loss": 1.6628352936261097,
      "val_quality": 0.5415621853207377,
      "patience_counter": 14
    },
    {
      "step": 35,
      "train_loss": 0.6430684041163763,
      "train_quality": 0.8307130169122758,
      "val_loss": 1.6761407130222206,
      "val_quality": 0.5378939282090891,
      "patience_counter": 15
    },
    {
      "step": 36,
      "train_loss": 0.6413340987975612,
      "train_quality": 0.8311695706992384,
      "val_loss": 1.6885643147604767,
      "val_quality": 0.5344687851097316,
      "patience_counter": 16
    },
    {
      "step": 37,
      "train_loss": 0.6397262515262212,
      "train_quality": 0.8315928345574666,
      "val_loss": 1.700698242034814,
      "val_quality": 0.5311235042364866,
      "patience_counter": 17
    },
    {
      "step": 38,
      "train_loss": 0.6382147102028487,
      "train_quality": 0.8319907459908509,
      "val_loss": 1.7129483445471527,
      "val_quality": 0.5277461942606398,
      "patience_counter": 18
    },
    {
      "step": 39,
      "train_loss": 0.6367812068016081,
      "train_quality": 0.8323681140351968,
      "val_loss": 1.7255718130229174,
      "val_quality": 0.5242659486079977,
      "patience_counter": 19
    },
    {
      "step": 40,
      "train_loss": 0.6354162755895068,
      "train_quality": 0.8327274305333171,
      "val_loss": 1.7387054969510054,
      "val_quality": 0.5206450383580408,
      "patience_counter": 20
    }
  ],
  "summary": {
    "test_quality": 0.6867072391043549,
    "test_loss": 1.233840498128067,
    "best_val_quality": 0.6227944867413225,
    "n_parameters": 972
  }
}