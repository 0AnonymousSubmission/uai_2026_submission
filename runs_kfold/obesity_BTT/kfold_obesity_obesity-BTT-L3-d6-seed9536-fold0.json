{
  "experiment_name": "kfold_obesity",
  "run_name": "obesity-BTT-L3-d6-seed9536-fold0",
  "config": {
    "params": {
      "model": "BTT",
      "L": 3,
      "bond_dim": 6,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 0,
    "seed": 9536
  },
  "hparams": {
    "seed": 9536,
    "fold": 0,
    "dataset": "obesity",
    "n_features": 40,
    "n_train": 1435,
    "n_val": 253,
    "n_test": 423,
    "L": 3,
    "bond_dim": 6,
    "model": "BTT",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 2.5778471262913025,
      "train_quality": 0.31693288974309475,
      "val_loss": 2.9367161379385704,
      "val_quality": 0.18875041744359444,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 1.371854197142321,
      "train_quality": 0.636491833600717,
      "val_loss": 1.7990207539086627,
      "val_quality": 0.5030316969473332,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 1.001912266286729,
      "train_quality": 0.7345174934993073,
      "val_loss": 1.6164121927637207,
      "val_quality": 0.5534761771224065,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 0.8825392889826446,
      "train_quality": 0.7661484439223347,
      "val_loss": 1.494905381548247,
      "val_quality": 0.5870416786030862,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 0.819992919702134,
      "train_quality": 0.7827217182975941,
      "val_loss": 1.3876175446510255,
      "val_quality": 0.6166792767937463,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 0.7792948194192609,
      "train_quality": 0.7935057300683628,
      "val_loss": 1.311897545833641,
      "val_quality": 0.6375964558966929,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 0.750404859949831,
      "train_quality": 0.8011608702545123,
      "val_loss": 1.2753110134284236,
      "val_quality": 0.6477032581025587,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 0.7300562314171625,
      "train_quality": 0.8065527644237752,
      "val_loss": 1.2621877225141067,
      "val_quality": 0.6513284856614874,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 0.7158189505493652,
      "train_quality": 0.8103252993429709,
      "val_loss": 1.2559392247204972,
      "val_quality": 0.6530545943449875,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 0.7050034251436347,
      "train_quality": 0.8131911518636481,
      "val_loss": 1.249885181336964,
      "val_quality": 0.6547269862061624,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 0.696120393763483,
      "train_quality": 0.8155449402296368,
      "val_loss": 1.2485567038090866,
      "val_quality": 0.6550939698672672,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 0.6884289595517653,
      "train_quality": 0.8175829841800115,
      "val_loss": 1.2522468086000553,
      "val_quality": 0.6540746013513288,
      "patience_counter": 1
    },
    {
      "step": 13,
      "train_loss": 0.6816359572578655,
      "train_quality": 0.8193829654122339,
      "val_loss": 1.2571416849571144,
      "val_quality": 0.6527224221774448,
      "patience_counter": 2
    },
    {
      "step": 14,
      "train_loss": 0.6756800932309519,
      "train_quality": 0.8209611252606032,
      "val_loss": 1.2612522058039102,
      "val_quality": 0.6515869163388066,
      "patience_counter": 3
    },
    {
      "step": 15,
      "train_loss": 0.6705674755966654,
      "train_quality": 0.8223158452196275,
      "val_loss": 1.2642591755041834,
      "val_quality": 0.6507562596462537,
      "patience_counter": 4
    },
    {
      "step": 16,
      "train_loss": 0.6662199230016056,
      "train_quality": 0.823467841456142,
      "val_loss": 1.2659797000113022,
      "val_quality": 0.6502809754435532,
      "patience_counter": 5
    },
    {
      "step": 17,
      "train_loss": 0.6624897533302498,
      "train_quality": 0.824456246157179,
      "val_loss": 1.2661773966050107,
      "val_quality": 0.6502263629881487,
      "patience_counter": 6
    },
    {
      "step": 18,
      "train_loss": 0.6592204651696619,
      "train_quality": 0.8253225284101777,
      "val_loss": 1.2649090970957155,
      "val_quality": 0.6505767228456031,
      "patience_counter": 7
    },
    {
      "step": 19,
      "train_loss": 0.6562731499109693,
      "train_quality": 0.8261034956352078,
      "val_loss": 1.2626031109249605,
      "val_quality": 0.6512137371944666,
      "patience_counter": 8
    },
    {
      "step": 20,
      "train_loss": 0.6535358668791292,
      "train_quality": 0.8268288094024381,
      "val_loss": 1.259945114215164,
      "val_quality": 0.6519479922671316,
      "patience_counter": 9
    },
    {
      "step": 21,
      "train_loss": 0.6509288378104775,
      "train_quality": 0.827519609021282,
      "val_loss": 1.257733878301125,
      "val_quality": 0.6525588324464133,
      "patience_counter": 10
    },
    {
      "step": 22,
      "train_loss": 0.6484020297701597,
      "train_quality": 0.8281891520087891,
      "val_loss": 1.2566833762701601,
      "val_quality": 0.6528490271040057,
      "patience_counter": 11
    },
    {
      "step": 23,
      "train_loss": 0.6459307465181024,
      "train_quality": 0.8288439822709845,
      "val_loss": 1.2571428519937713,
      "val_quality": 0.6527220997908211,
      "patience_counter": 12
    },
    {
      "step": 24,
      "train_loss": 0.6435149456761274,
      "train_quality": 0.82948411103706,
      "val_loss": 1.258897564848393,
      "val_quality": 0.65223737126959,
      "patience_counter": 13
    },
    {
      "step": 25,
      "train_loss": 0.641170084299342,
      "train_quality": 0.8301054425614387,
      "val_loss": 1.261316291145246,
      "val_quality": 0.651569213161528,
      "patience_counter": 14
    },
    {
      "step": 26,
      "train_loss": 0.6389132606791816,
      "train_quality": 0.8307034462106311,
      "val_loss": 1.263737433542293,
      "val_quality": 0.6509003876208026,
      "patience_counter": 15
    },
    {
      "step": 27,
      "train_loss": 0.6367595227787319,
      "train_quality": 0.8312741346385472,
      "val_loss": 1.2657026351240035,
      "val_quality": 0.6503575128968189,
      "patience_counter": 16
    },
    {
      "step": 28,
      "train_loss": 0.6347240914409193,
      "train_quality": 0.831813474690122,
      "val_loss": 1.2669624866258447,
      "val_quality": 0.6500094867489226,
      "patience_counter": 17
    },
    {
      "step": 29,
      "train_loss": 0.632821638659765,
      "train_quality": 0.8323175786419699,
      "val_loss": 1.2674129168354704,
      "val_quality": 0.6498850582027621,
      "patience_counter": 18
    },
    {
      "step": 30,
      "train_loss": 0.6310632688327487,
      "train_quality": 0.8327835040974607,
      "val_loss": 1.267047371253319,
      "val_quality": 0.6499860378981077,
      "patience_counter": 19
    },
    {
      "step": 31,
      "train_loss": 0.6294545655828013,
      "train_quality": 0.8332097715316291,
      "val_loss": 1.265925385503379,
      "val_quality": 0.6502959794888235,
      "patience_counter": 20
    }
  ],
  "summary": {
    "test_quality": 0.7117636288860799,
    "test_loss": 1.161811867136023,
    "best_val_quality": 0.6550939698672672,
    "n_parameters": 972
  }
}