{
  "experiment_name": "kfold_bike",
  "run_name": "bike-LMPO2-L4-d8-seed42806-fold2",
  "config": {
    "params": {
      "model": "LMPO2",
      "L": 4,
      "bond_dim": 8,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": false,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 2,
    "seed": 42806
  },
  "hparams": {
    "seed": 42806,
    "fold": 2,
    "dataset": "bike",
    "n_features": 12,
    "n_train": 11818,
    "n_val": 2085,
    "n_test": 3476,
    "L": 4,
    "bond_dim": 8,
    "model": "LMPO2",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": false,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 19566.511282616415,
      "train_quality": 0.40568618962764,
      "val_loss": 22024.77363277845,
      "val_quality": 0.3235466941397903,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 16543.97368003655,
      "train_quality": 0.49749283893966667,
      "val_loss": 18230.820831786114,
      "val_quality": 0.44007147470277264,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 15533.505534910042,
      "train_quality": 0.5281848291936249,
      "val_loss": 16836.14725660671,
      "val_quality": 0.48290649159129684,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 14951.539997056258,
      "train_quality": 0.5458614681872387,
      "val_loss": 16137.305621286941,
      "val_quality": 0.5043702188634476,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 14565.281740658256,
      "train_quality": 0.557593688245887,
      "val_loss": 15753.731779967973,
      "val_quality": 0.5161510342910149,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 14248.055187029238,
      "train_quality": 0.5672291372595316,
      "val_loss": 15428.419848753236,
      "val_quality": 0.5261424346556696,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 13947.82254988437,
      "train_quality": 0.5763484125356629,
      "val_loss": 15102.936111615576,
      "val_quality": 0.5361391117458181,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 13669.625550266146,
      "train_quality": 0.5847983766855906,
      "val_loss": 14797.221978407235,
      "val_quality": 0.5455285992159276,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 13428.221182249028,
      "train_quality": 0.5921308003212875,
      "val_loss": 14517.086109378397,
      "val_quality": 0.5541324939870664,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 13225.786353057107,
      "train_quality": 0.5982795619963448,
      "val_loss": 14258.119930235016,
      "val_quality": 0.5620861978892404,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 13058.194409614767,
      "train_quality": 0.6033700047971222,
      "val_loss": 14028.818780197242,
      "val_quality": 0.569128791087554,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 12919.25284788274,
      "train_quality": 0.607590220030147,
      "val_loss": 13837.049406641821,
      "val_quality": 0.5750186598720051,
      "patience_counter": 0
    },
    {
      "step": 13,
      "train_loss": 12803.850305366748,
      "train_quality": 0.6110954603756893,
      "val_loss": 13684.810631454684,
      "val_quality": 0.57969441384217,
      "patience_counter": 0
    },
    {
      "step": 14,
      "train_loss": 12708.451459780614,
      "train_quality": 0.6139931078206783,
      "val_loss": 13566.618336454914,
      "val_quality": 0.5833244883216104,
      "patience_counter": 0
    },
    {
      "step": 15,
      "train_loss": 12629.928555971252,
      "train_quality": 0.6163781648955133,
      "val_loss": 13473.96104605686,
      "val_quality": 0.5861702987461286,
      "patience_counter": 0
    },
    {
      "step": 16,
      "train_loss": 12565.02131857045,
      "train_quality": 0.6183496593036496,
      "val_loss": 13399.643373558818,
      "val_quality": 0.5884528391292142,
      "patience_counter": 0
    },
    {
      "step": 17,
      "train_loss": 12510.57981240197,
      "train_quality": 0.6200032672721865,
      "val_loss": 13338.555048521734,
      "val_quality": 0.590329062699535,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 12463.966398462348,
      "train_quality": 0.6214191045286488,
      "val_loss": 13287.085212699418,
      "val_quality": 0.5919098708011117,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 12423.222900627576,
      "train_quality": 0.6226566487743415,
      "val_loss": 13242.801616687346,
      "val_quality": 0.5932699658203477,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 12386.970824700322,
      "train_quality": 0.6237577704340507,
      "val_loss": 13204.24951338653,
      "val_quality": 0.5944540278298156,
      "patience_counter": 0
    },
    {
      "step": 21,
      "train_loss": 12354.250494599468,
      "train_quality": 0.6247516187383295,
      "val_loss": 13170.640073095301,
      "val_quality": 0.5954862843865538,
      "patience_counter": 0
    },
    {
      "step": 22,
      "train_loss": 12324.416177430354,
      "train_quality": 0.6256578071978116,
      "val_loss": 13141.522470320775,
      "val_quality": 0.5963805818256085,
      "patience_counter": 0
    },
    {
      "step": 23,
      "train_loss": 12297.064611784956,
      "train_quality": 0.6264885844868017,
      "val_loss": 13116.545215181714,
      "val_quality": 0.5971477155583697,
      "patience_counter": 0
    },
    {
      "step": 24,
      "train_loss": 12271.95565645028,
      "train_quality": 0.6272512446618262,
      "val_loss": 13095.325152129111,
      "val_quality": 0.5977994535531308,
      "patience_counter": 0
    },
    {
      "step": 25,
      "train_loss": 12248.928321231126,
      "train_quality": 0.6279506776439837,
      "val_loss": 13077.413929880027,
      "val_quality": 0.5983495661538051,
      "patience_counter": 0
    },
    {
      "step": 26,
      "train_loss": 12227.83784227312,
      "train_quality": 0.6285912804950011,
      "val_loss": 13062.332299378746,
      "val_quality": 0.5988127726766258,
      "patience_counter": 0
    },
    {
      "step": 27,
      "train_loss": 12208.526641768734,
      "train_quality": 0.62917783948801,
      "val_loss": 13049.624196284592,
      "val_quality": 0.5992030803589012,
      "patience_counter": 0
    },
    {
      "step": 28,
      "train_loss": 12190.822163190052,
      "train_quality": 0.6297155958602509,
      "val_loss": 13038.89191877054,
      "val_quality": 0.5995327039330108,
      "patience_counter": 0
    },
    {
      "step": 29,
      "train_loss": 12174.547130074265,
      "train_quality": 0.6302099342124116,
      "val_loss": 13029.803668661087,
      "val_quality": 0.5998118340132345,
      "patience_counter": 0
    },
    {
      "step": 30,
      "train_loss": 12159.531425592091,
      "train_quality": 0.6306660216782519,
      "val_loss": 13022.085180422015,
      "val_quality": 0.6000488941970354,
      "patience_counter": 0
    },
    {
      "step": 31,
      "train_loss": 12145.62080008399,
      "train_quality": 0.6310885434416349,
      "val_loss": 13015.509921184663,
      "val_quality": 0.6002508420545778,
      "patience_counter": 0
    },
    {
      "step": 32,
      "train_loss": 12132.68141261999,
      "train_quality": 0.6314815647910487,
      "val_loss": 13009.893059786287,
      "val_quality": 0.6004233543593507,
      "patience_counter": 0
    },
    {
      "step": 33,
      "train_loss": 12120.600785936569,
      "train_quality": 0.6318485021143255,
      "val_loss": 13005.087874026212,
      "val_quality": 0.6005709374331598,
      "patience_counter": 0
    },
    {
      "step": 34,
      "train_loss": 12109.286213893358,
      "train_quality": 0.6321921712706,
      "val_loss": 13000.981796085678,
      "val_quality": 0.6006970486043031,
      "patience_counter": 0
    },
    {
      "step": 35,
      "train_loss": 12098.661726745142,
      "train_quality": 0.6325148797672302,
      "val_loss": 12997.490714803685,
      "val_quality": 0.6008042712034364,
      "patience_counter": 0
    },
    {
      "step": 36,
      "train_loss": 12088.664587068679,
      "train_quality": 0.6328185331926224,
      "val_loss": 12994.552240045894,
      "val_quality": 0.6008945214369796,
      "patience_counter": 1
    },
    {
      "step": 37,
      "train_loss": 12079.2420553902,
      "train_quality": 0.6331047334571616,
      "val_loss": 12992.118294862508,
      "val_quality": 0.6009692759063346,
      "patience_counter": 0
    },
    {
      "step": 38,
      "train_loss": 12070.348836960758,
      "train_quality": 0.6333748563449331,
      "val_loss": 12990.148529037713,
      "val_quality": 0.6010297738994659,
      "patience_counter": 1
    },
    {
      "step": 39,
      "train_loss": 12061.945318249569,
      "train_quality": 0.6336301050785291,
      "val_loss": 12988.604918278807,
      "val_quality": 0.6010771832675817,
      "patience_counter": 0
    },
    {
      "step": 40,
      "train_loss": 12053.99645334436,
      "train_quality": 0.633871544143558,
      "val_loss": 12987.447865586166,
      "val_quality": 0.6011127201648975,
      "patience_counter": 1
    },
    {
      "step": 41,
      "train_loss": 12046.471058306539,
      "train_quality": 0.6341001207219211,
      "val_loss": 12986.63433556336,
      "val_quality": 0.6011377063501141,
      "patience_counter": 2
    },
    {
      "step": 42,
      "train_loss": 12039.341283664557,
      "train_quality": 0.6343166807143168,
      "val_loss": 12986.117742658971,
      "val_quality": 0.6011535726188797,
      "patience_counter": 3
    },
    {
      "step": 43,
      "train_loss": 12032.58211755235,
      "train_quality": 0.6345219838319274,
      "val_loss": 12985.849522874412,
      "val_quality": 0.6011618105314679,
      "patience_counter": 4
    },
    {
      "step": 44,
      "train_loss": 12026.170852825348,
      "train_quality": 0.6347167197822547,
      "val_loss": 12985.781512408095,
      "val_quality": 0.6011638993567853,
      "patience_counter": 5
    },
    {
      "step": 45,
      "train_loss": 12020.086534644332,
      "train_quality": 0.6349015250482242,
      "val_loss": 12985.868647128853,
      "val_quality": 0.6011612231626552,
      "patience_counter": 6
    },
    {
      "step": 46,
      "train_loss": 12014.309426525733,
      "train_quality": 0.6350769991063894,
      "val_loss": 12986.07113595377,
      "val_quality": 0.60115500406423,
      "patience_counter": 7
    },
    {
      "step": 47,
      "train_loss": 12008.820554339101,
      "train_quality": 0.6352437182775675,
      "val_loss": 12986.356117812593,
      "val_quality": 0.6011462513331589,
      "patience_counter": 8
    },
    {
      "step": 48,
      "train_loss": 12003.601363814867,
      "train_quality": 0.635402246129708,
      "val_loss": 12986.698129214628,
      "val_quality": 0.6011357470370691,
      "patience_counter": 9
    },
    {
      "step": 49,
      "train_loss": 11998.633517275708,
      "train_quality": 0.6355531396519813,
      "val_loss": 12987.079231780606,
      "val_quality": 0.6011240421226429,
      "patience_counter": 10
    },
    {
      "step": 50,
      "train_loss": 11993.89882794194,
      "train_quality": 0.6356969512501879,
      "val_loss": 12987.488344578545,
      "val_quality": 0.6011114769217809,
      "patience_counter": 11
    }
  ],
  "summary": {
    "test_quality": 0.5860132980651633,
    "test_loss": 13670.416407599927,
    "best_val_quality": 0.6010771832675817,
    "n_parameters": 1152
  }
}