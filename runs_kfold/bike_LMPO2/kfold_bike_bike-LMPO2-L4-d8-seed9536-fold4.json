{
  "experiment_name": "kfold_bike",
  "run_name": "bike-LMPO2-L4-d8-seed9536-fold4",
  "config": {
    "params": {
      "model": "LMPO2",
      "L": 4,
      "bond_dim": 8,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": false,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 4,
    "seed": 9536
  },
  "hparams": {
    "seed": 9536,
    "fold": 4,
    "dataset": "bike",
    "n_features": 12,
    "n_train": 11819,
    "n_val": 2085,
    "n_test": 3475,
    "L": 4,
    "bond_dim": 8,
    "model": "LMPO2",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": false,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 18409.34202889885,
      "train_quality": 0.4440114605848351,
      "val_loss": 19910.90901122688,
      "val_quality": 0.36746247824381895,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 14913.702609666778,
      "train_quality": 0.5495847859090084,
      "val_loss": 16728.605240430432,
      "val_quality": 0.46855914537840004,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 13995.302743116916,
      "train_quality": 0.5773217794202687,
      "val_loss": 15360.897467327555,
      "val_quality": 0.5120090192539399,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 13588.547114498708,
      "train_quality": 0.5896063829383806,
      "val_loss": 14822.216301949384,
      "val_quality": 0.5291220525751668,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 13339.859651939285,
      "train_quality": 0.5971171010760645,
      "val_loss": 14509.728147886764,
      "val_quality": 0.5390492981086319,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 13165.111236874967,
      "train_quality": 0.6023947539060357,
      "val_loss": 14308.431895064314,
      "val_quality": 0.5454441559640579,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 13035.529147043651,
      "train_quality": 0.6063083189181138,
      "val_loss": 14177.176963919454,
      "val_quality": 0.5496139137997165,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 12931.37062673542,
      "train_quality": 0.6094540556578033,
      "val_loss": 14084.907629659383,
      "val_quality": 0.5525451619910497,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 12843.203091626112,
      "train_quality": 0.6121168417037308,
      "val_loss": 14018.4724480339,
      "val_quality": 0.5546557007474224,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 12767.561295245054,
      "train_quality": 0.6144013324705722,
      "val_loss": 13971.25954981713,
      "val_quality": 0.5561555785087101,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 12703.061141053953,
      "train_quality": 0.6163493296594162,
      "val_loss": 13935.831268341652,
      "val_quality": 0.5572810779699322,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 12648.287938534108,
      "train_quality": 0.6180035589534505,
      "val_loss": 13904.69914850374,
      "val_quality": 0.5582700952929578,
      "patience_counter": 0
    },
    {
      "step": 13,
      "train_loss": 12601.507699554257,
      "train_quality": 0.6194163892818279,
      "val_loss": 13874.206218391097,
      "val_quality": 0.5592388065875382,
      "patience_counter": 0
    },
    {
      "step": 14,
      "train_loss": 12561.106757841646,
      "train_quality": 0.6206365556809599,
      "val_loss": 13844.122881076122,
      "val_quality": 0.5601945057784008,
      "patience_counter": 0
    },
    {
      "step": 15,
      "train_loss": 12525.847702327848,
      "train_quality": 0.6217014297403097,
      "val_loss": 13815.35134731216,
      "val_quality": 0.5611085310825152,
      "patience_counter": 0
    },
    {
      "step": 16,
      "train_loss": 12494.843384920327,
      "train_quality": 0.6226378046049796,
      "val_loss": 13788.685491782286,
      "val_quality": 0.5619556623793769,
      "patience_counter": 0
    },
    {
      "step": 17,
      "train_loss": 12467.433112554769,
      "train_quality": 0.6234656341533457,
      "val_loss": 13764.588831404102,
      "val_quality": 0.5627211744827982,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 12443.076245737027,
      "train_quality": 0.6242012464737354,
      "val_loss": 13743.246780523767,
      "val_quality": 0.5633991770775281,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 12421.299347276597,
      "train_quality": 0.6248589400484976,
      "val_loss": 13724.630324539596,
      "val_quality": 0.5639905919107469,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 12401.684622456281,
      "train_quality": 0.6254513328774622,
      "val_loss": 13708.57850352057,
      "val_quality": 0.5645005324203101,
      "patience_counter": 0
    },
    {
      "step": 21,
      "train_loss": 12383.872863818217,
      "train_quality": 0.6259892735411778,
      "val_loss": 13694.896588224896,
      "val_quality": 0.5649351848407054,
      "patience_counter": 0
    },
    {
      "step": 22,
      "train_loss": 12367.564097206325,
      "train_quality": 0.6264818216895025,
      "val_loss": 13683.421563765076,
      "val_quality": 0.5652997278924472,
      "patience_counter": 0
    },
    {
      "step": 23,
      "train_loss": 12352.512563888167,
      "train_quality": 0.6269363995887225,
      "val_loss": 13674.029014264868,
      "val_quality": 0.5655981140676081,
      "patience_counter": 0
    },
    {
      "step": 24,
      "train_loss": 12338.51852567235,
      "train_quality": 0.6273590396187636,
      "val_loss": 13666.600645369079,
      "val_quality": 0.5658341013873925,
      "patience_counter": 0
    },
    {
      "step": 25,
      "train_loss": 12325.419719666548,
      "train_quality": 0.6277546423517575,
      "val_loss": 13660.988107321205,
      "val_quality": 0.5660124026847146,
      "patience_counter": 0
    },
    {
      "step": 26,
      "train_loss": 12313.084007845986,
      "train_quality": 0.6281271985456178,
      "val_loss": 13656.995675759932,
      "val_quality": 0.5661392358074075,
      "patience_counter": 0
    },
    {
      "step": 27,
      "train_loss": 12301.403794537166,
      "train_quality": 0.6284799577440419,
      "val_loss": 13654.385476371637,
      "val_quality": 0.566222157639426,
      "patience_counter": 1
    },
    {
      "step": 28,
      "train_loss": 12290.292016450181,
      "train_quality": 0.6288155493832862,
      "val_loss": 13652.896759057738,
      "val_quality": 0.5662694517915814,
      "patience_counter": 0
    },
    {
      "step": 29,
      "train_loss": 12279.679152459054,
      "train_quality": 0.6291360731010909,
      "val_loss": 13652.269172409147,
      "val_quality": 0.5662893892089621,
      "patience_counter": 1
    },
    {
      "step": 30,
      "train_loss": 12269.51068599972,
      "train_quality": 0.6294431753759001,
      "val_loss": 13652.262922334932,
      "val_quality": 0.566289587763757,
      "patience_counter": 2
    },
    {
      "step": 31,
      "train_loss": 12259.74468988956,
      "train_quality": 0.6297381224687781,
      "val_loss": 13652.672545117117,
      "val_quality": 0.5662765747074796,
      "patience_counter": 3
    },
    {
      "step": 32,
      "train_loss": 12250.34946590422,
      "train_quality": 0.630021871711575,
      "val_loss": 13653.334124284169,
      "val_quality": 0.566255557402517,
      "patience_counter": 4
    },
    {
      "step": 33,
      "train_loss": 12241.301297388469,
      "train_quality": 0.6302951393813025,
      "val_loss": 13654.126111157953,
      "val_quality": 0.5662303972546741,
      "patience_counter": 5
    },
    {
      "step": 34,
      "train_loss": 12232.582430475126,
      "train_quality": 0.6305584616702196,
      "val_loss": 13654.96569633211,
      "val_quality": 0.566203724985464,
      "patience_counter": 6
    },
    {
      "step": 35,
      "train_loss": 12224.179330863308,
      "train_quality": 0.630812247333629,
      "val_loss": 13655.80168346924,
      "val_quality": 0.5661771670200972,
      "patience_counter": 7
    },
    {
      "step": 36,
      "train_loss": 12216.08122337842,
      "train_quality": 0.6310568217972616,
      "val_loss": 13656.605973475615,
      "val_quality": 0.5661516160215407,
      "patience_counter": 8
    },
    {
      "step": 37,
      "train_loss": 12208.278877592566,
      "train_quality": 0.6312924638332823,
      "val_loss": 13657.365043976582,
      "val_quality": 0.5661275015738654,
      "patience_counter": 9
    },
    {
      "step": 38,
      "train_loss": 12200.763610080567,
      "train_quality": 0.6315194356935883,
      "val_loss": 13658.0727511438,
      "val_quality": 0.5661050188566058,
      "patience_counter": 10
    },
    {
      "step": 39,
      "train_loss": 12193.52648635626,
      "train_quality": 0.6317380072124795,
      "val_loss": 13658.725187142676,
      "val_quality": 0.5660842920153751,
      "patience_counter": 11
    },
    {
      "step": 40,
      "train_loss": 12186.5577499537,
      "train_quality": 0.6319484730492241,
      "val_loss": 13659.317744725777,
      "val_quality": 0.5660654674150065,
      "patience_counter": 12
    },
    {
      "step": 41,
      "train_loss": 12179.846525451674,
      "train_quality": 0.6321511616571445,
      "val_loss": 13659.844018852995,
      "val_quality": 0.5660487485333117,
      "patience_counter": 13
    },
    {
      "step": 42,
      "train_loss": 12173.380823779833,
      "train_quality": 0.632346435123365,
      "val_loss": 13660.296038073931,
      "val_quality": 0.5660343886104355,
      "patience_counter": 14
    },
    {
      "step": 43,
      "train_loss": 12167.147816863828,
      "train_quality": 0.6325346808741341,
      "val_loss": 13660.665083185322,
      "val_quality": 0.566022664641427,
      "patience_counter": 15
    },
    {
      "step": 44,
      "train_loss": 12161.134322828339,
      "train_quality": 0.6327162970209972,
      "val_loss": 13660.9427151229,
      "val_quality": 0.5660138447217712,
      "patience_counter": 16
    },
    {
      "step": 45,
      "train_loss": 12155.32736028353,
      "train_quality": 0.6328916756205505,
      "val_loss": 13661.121463510655,
      "val_quality": 0.5660081661732858,
      "patience_counter": 17
    },
    {
      "step": 46,
      "train_loss": 12149.714674204939,
      "train_quality": 0.633061186792114,
      "val_loss": 13661.195372765858,
      "val_quality": 0.5660058181952454,
      "patience_counter": 18
    },
    {
      "step": 47,
      "train_loss": 12144.285138691577,
      "train_quality": 0.6332251665538587,
      "val_loss": 13661.160425235135,
      "val_quality": 0.5660069284220293,
      "patience_counter": 19
    },
    {
      "step": 48,
      "train_loss": 12139.028987444015,
      "train_quality": 0.6333839098620384,
      "val_loss": 13661.01476553557,
      "val_quality": 0.5660115557961654,
      "patience_counter": 20
    }
  ],
  "summary": {
    "test_quality": 0.5836622037282582,
    "test_loss": 13750.104043677942,
    "best_val_quality": 0.5662694517915814,
    "n_parameters": 1152
  }
}