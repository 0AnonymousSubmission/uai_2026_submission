{
  "experiment_name": "kfold_bike",
  "run_name": "bike-BTT-L4-d6-seed9536-fold0",
  "config": {
    "params": {
      "model": "BTT",
      "L": 4,
      "bond_dim": 6,
      "init_strength": 0.01,
      "bond_prior_alpha": 1.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 0,
    "seed": 9536
  },
  "hparams": {
    "seed": 9536,
    "fold": 0,
    "dataset": "bike",
    "n_features": 13,
    "n_train": 11818,
    "n_val": 2085,
    "n_test": 3476,
    "L": 4,
    "bond_dim": 6,
    "model": "BTT",
    "init_strength": 0.01,
    "bond_prior_alpha": 1.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 13779.175567453583,
      "train_quality": 0.5834447203076019,
      "val_loss": 13933.18964831522,
      "val_quality": 0.564452464868575,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 11803.528241017199,
      "train_quality": 0.6431700878093481,
      "val_loss": 11651.491375974721,
      "val_quality": 0.6357777021986865,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 11254.006714267565,
      "train_quality": 0.6597825543645217,
      "val_loss": 11127.382406514245,
      "val_quality": 0.6521611991258516,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 11048.441853578532,
      "train_quality": 0.665996941257269,
      "val_loss": 10990.787812861485,
      "val_quality": 0.6564311071712741,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 10933.61399067388,
      "train_quality": 0.6694682775730431,
      "val_loss": 10911.628073736236,
      "val_quality": 0.6589056180426465,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 10857.220448528073,
      "train_quality": 0.6717777142414025,
      "val_loss": 10860.58077774718,
      "val_quality": 0.6605013419583003,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 10800.241483718706,
      "train_quality": 0.6735002330166775,
      "val_loss": 10818.420195204646,
      "val_quality": 0.6618192697458063,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 10753.49068565612,
      "train_quality": 0.6749135462927491,
      "val_loss": 10778.675403001655,
      "val_quality": 0.6630616806162,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 10713.41715602323,
      "train_quality": 0.6761250005094962,
      "val_loss": 10740.925131084008,
      "val_quality": 0.6642417433512436,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 10678.809044899674,
      "train_quality": 0.6771712308400502,
      "val_loss": 10708.186209108444,
      "val_quality": 0.6652651527161654,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 10649.71369754397,
      "train_quality": 0.6780508060001293,
      "val_loss": 10683.93605466557,
      "val_quality": 0.666023205628725,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 10626.031101952298,
      "train_quality": 0.6787667494310144,
      "val_loss": 10667.859131694946,
      "val_quality": 0.6665257656561914,
      "patience_counter": 0
    },
    {
      "step": 13,
      "train_loss": 10606.76260171521,
      "train_quality": 0.6793492512988673,
      "val_loss": 10656.520346038877,
      "val_quality": 0.6668802128623617,
      "patience_counter": 0
    },
    {
      "step": 14,
      "train_loss": 10590.663925585895,
      "train_quality": 0.6798359268989347,
      "val_loss": 10646.695760343067,
      "val_quality": 0.6671873266095727,
      "patience_counter": 0
    },
    {
      "step": 15,
      "train_loss": 10576.801270295806,
      "train_quality": 0.6802550058360868,
      "val_loss": 10636.949403635113,
      "val_quality": 0.6674919949409318,
      "patience_counter": 0
    },
    {
      "step": 16,
      "train_loss": 10564.567011989942,
      "train_quality": 0.6806248570558119,
      "val_loss": 10627.137569382401,
      "val_quality": 0.667798710081668,
      "patience_counter": 0
    },
    {
      "step": 17,
      "train_loss": 10553.557074478553,
      "train_quality": 0.6809576960981045,
      "val_loss": 10617.608094990206,
      "val_quality": 0.6680965987336839,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 10543.489213154906,
      "train_quality": 0.6812620554386939,
      "val_loss": 10608.745133859033,
      "val_quality": 0.6683736523712274,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 10534.162499464912,
      "train_quality": 0.6815440093052898,
      "val_loss": 10600.795325572995,
      "val_quality": 0.6686221611112321,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 10525.434736644902,
      "train_quality": 0.6818078564175339,
      "val_loss": 10593.841160360045,
      "val_quality": 0.6688395463326959,
      "patience_counter": 0
    },
    {
      "step": 21,
      "train_loss": 10517.206453084365,
      "train_quality": 0.6820566038801937,
      "val_loss": 10587.837111919865,
      "val_quality": 0.6690272311747842,
      "patience_counter": 0
    },
    {
      "step": 22,
      "train_loss": 10509.408540624127,
      "train_quality": 0.6822923408870989,
      "val_loss": 10582.664516311588,
      "val_quality": 0.6691889250384495,
      "patience_counter": 0
    },
    {
      "step": 23,
      "train_loss": 10501.992999240108,
      "train_quality": 0.6825165185166071,
      "val_loss": 10578.183146226722,
      "val_quality": 0.6693290113893671,
      "patience_counter": 0
    },
    {
      "step": 24,
      "train_loss": 10494.926120795857,
      "train_quality": 0.6827301557921093,
      "val_loss": 10574.268248206727,
      "val_quality": 0.6694513899850755,
      "patience_counter": 0
    },
    {
      "step": 25,
      "train_loss": 10488.183263899213,
      "train_quality": 0.6829339976422082,
      "val_loss": 10570.829246992615,
      "val_quality": 0.6695588921823417,
      "patience_counter": 0
    },
    {
      "step": 26,
      "train_loss": 10481.744771796446,
      "train_quality": 0.6831286383059791,
      "val_loss": 10567.81251800873,
      "val_quality": 0.6696531942701087,
      "patience_counter": 1
    },
    {
      "step": 27,
      "train_loss": 10475.593078057052,
      "train_quality": 0.6833146088303876,
      "val_loss": 10565.194063709958,
      "val_quality": 0.6697350464047938,
      "patience_counter": 0
    },
    {
      "step": 28,
      "train_loss": 10469.711126935683,
      "train_quality": 0.6834924248239864,
      "val_loss": 10562.96812783495,
      "val_quality": 0.6698046285254846,
      "patience_counter": 1
    },
    {
      "step": 29,
      "train_loss": 10464.081947315331,
      "train_quality": 0.6836625993369473,
      "val_loss": 10561.136047510801,
      "val_quality": 0.6698618988339702,
      "patience_counter": 0
    },
    {
      "step": 30,
      "train_loss": 10458.688924660708,
      "train_quality": 0.6838256346396971,
      "val_loss": 10559.697534646388,
      "val_quality": 0.6699068663358965,
      "patience_counter": 1
    },
    {
      "step": 31,
      "train_loss": 10453.516261170194,
      "train_quality": 0.6839820083121638,
      "val_loss": 10558.6449787958,
      "val_quality": 0.6699397689316324,
      "patience_counter": 2
    },
    {
      "step": 32,
      "train_loss": 10448.549281535932,
      "train_quality": 0.6841321640004085,
      "val_loss": 10557.960516315623,
      "val_quality": 0.6699611650335773,
      "patience_counter": 3
    },
    {
      "step": 33,
      "train_loss": 10443.774469345051,
      "train_quality": 0.6842765103161889,
      "val_loss": 10557.615313874248,
      "val_quality": 0.6699719559634546,
      "patience_counter": 0
    },
    {
      "step": 34,
      "train_loss": 10439.179280858201,
      "train_quality": 0.6844154264665789,
      "val_loss": 10557.57049266081,
      "val_quality": 0.6699733570618052,
      "patience_counter": 1
    },
    {
      "step": 35,
      "train_loss": 10434.75184434054,
      "train_quality": 0.6845492713434299,
      "val_loss": 10557.779150812374,
      "val_quality": 0.6699668344674895,
      "patience_counter": 2
    },
    {
      "step": 36,
      "train_loss": 10430.480645757458,
      "train_quality": 0.6846783930250347,
      "val_loss": 10558.18899107579,
      "val_quality": 0.6699540229777277,
      "patience_counter": 3
    },
    {
      "step": 37,
      "train_loss": 10426.354269354979,
      "train_quality": 0.6848031366185855,
      "val_loss": 10558.74513686761,
      "val_quality": 0.6699366380188694,
      "patience_counter": 4
    },
    {
      "step": 38,
      "train_loss": 10422.361231808507,
      "train_quality": 0.6849238492739871,
      "val_loss": 10559.392809757941,
      "val_quality": 0.6699163919490121,
      "patience_counter": 5
    },
    {
      "step": 39,
      "train_loss": 10418.48992854711,
      "train_quality": 0.6850408818065166,
      "val_loss": 10560.07966181775,
      "val_quality": 0.6698949211494895,
      "patience_counter": 6
    },
    {
      "step": 40,
      "train_loss": 10414.728693804054,
      "train_quality": 0.6851545868814473,
      "val_loss": 10560.757642713761,
      "val_quality": 0.6698737276600174,
      "patience_counter": 7
    },
    {
      "step": 41,
      "train_loss": 10411.06595818805,
      "train_quality": 0.6852653142505483,
      "val_loss": 10561.384364098372,
      "val_quality": 0.6698541365282542,
      "patience_counter": 8
    },
    {
      "step": 42,
      "train_loss": 10407.490471615138,
      "train_quality": 0.6853734040126769,
      "val_loss": 10561.923968330588,
      "val_quality": 0.6698372686538321,
      "patience_counter": 9
    },
    {
      "step": 43,
      "train_loss": 10403.99155178071,
      "train_quality": 0.6854791791022763,
      "val_loss": 10562.347546587265,
      "val_quality": 0.6698240277183185,
      "patience_counter": 10
    },
    {
      "step": 44,
      "train_loss": 10400.559322049687,
      "train_quality": 0.6855829380977674,
      "val_loss": 10562.633174851571,
      "val_quality": 0.6698150990602278,
      "patience_counter": 11
    },
    {
      "step": 45,
      "train_loss": 10397.184914974097,
      "train_quality": 0.6856849490690542,
      "val_loss": 10562.765639727539,
      "val_quality": 0.6698109582459797,
      "patience_counter": 12
    },
    {
      "step": 46,
      "train_loss": 10393.860631737363,
      "train_quality": 0.6857854447573974,
      "val_loss": 10562.73594194707,
      "val_quality": 0.6698118865901284,
      "patience_counter": 13
    },
    {
      "step": 47,
      "train_loss": 10390.580058454696,
      "train_quality": 0.6858846190595627,
      "val_loss": 10562.540645947633,
      "val_quality": 0.6698179914873789,
      "patience_counter": 14
    },
    {
      "step": 48,
      "train_loss": 10387.338144510704,
      "train_quality": 0.6859826246596124,
      "val_loss": 10562.181151047127,
      "val_quality": 0.6698292291954528,
      "patience_counter": 15
    },
    {
      "step": 49,
      "train_loss": 10384.131247053023,
      "train_quality": 0.6860795716838294,
      "val_loss": 10561.662927277426,
      "val_quality": 0.6698454287227138,
      "patience_counter": 16
    },
    {
      "step": 50,
      "train_loss": 10380.957142053947,
      "train_quality": 0.6861755273663149,
      "val_loss": 10560.994752857634,
      "val_quality": 0.6698663156645357,
      "patience_counter": 17
    }
  ],
  "summary": {
    "test_quality": 0.6705005801290629,
    "test_loss": 10816.828601746703,
    "best_val_quality": 0.6699719559634546,
    "n_parameters": 780
  }
}