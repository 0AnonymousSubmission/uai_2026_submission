{
  "experiment_name": "kfold_obesity",
  "run_name": "obesity-MPO2-L3-d10-seed47659-fold0",
  "config": {
    "params": {
      "model": "MPO2",
      "L": 3,
      "bond_dim": 10,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": false,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 0,
    "seed": 47659
  },
  "hparams": {
    "seed": 47659,
    "fold": 0,
    "dataset": "obesity",
    "n_features": 39,
    "n_train": 1435,
    "n_val": 253,
    "n_test": 423,
    "L": 3,
    "bond_dim": 10,
    "model": "MPO2",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": false,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 1.3266007870141923,
      "train_quality": 0.6627684031231243,
      "val_loss": 1.6843020320846351,
      "val_quality": 0.553938083809671,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 0.6406248309266349,
      "train_quality": 0.8371484949751833,
      "val_loss": 1.0633605897841727,
      "val_quality": 0.7183850323487755,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 0.5345898828417003,
      "train_quality": 0.8641033522445816,
      "val_loss": 1.0848969317569293,
      "val_quality": 0.7126814579392569,
      "patience_counter": 1
    },
    {
      "step": 4,
      "train_loss": 0.4862212940995377,
      "train_quality": 0.8763990003249004,
      "val_loss": 1.091532833294161,
      "val_quality": 0.7109240397927714,
      "patience_counter": 2
    },
    {
      "step": 5,
      "train_loss": 0.4588275456794473,
      "train_quality": 0.8833626909955072,
      "val_loss": 1.097543815920974,
      "val_quality": 0.7093321219670923,
      "patience_counter": 3
    },
    {
      "step": 6,
      "train_loss": 0.443524500076208,
      "train_quality": 0.8872528368150912,
      "val_loss": 1.1097685263248234,
      "val_quality": 0.7060945923294514,
      "patience_counter": 4
    },
    {
      "step": 7,
      "train_loss": 0.4341852045410886,
      "train_quality": 0.8896269538651059,
      "val_loss": 1.1209210287138123,
      "val_quality": 0.7031410207661656,
      "patience_counter": 5
    },
    {
      "step": 8,
      "train_loss": 0.42789196441390087,
      "train_quality": 0.8912267414111377,
      "val_loss": 1.1271250484876714,
      "val_quality": 0.7014979799720005,
      "patience_counter": 6
    },
    {
      "step": 9,
      "train_loss": 0.42339202646793594,
      "train_quality": 0.8923706584615565,
      "val_loss": 1.1289925577714093,
      "val_quality": 0.7010033983864303,
      "patience_counter": 7
    },
    {
      "step": 10,
      "train_loss": 0.42007050136138563,
      "train_quality": 0.8932150143723273,
      "val_loss": 1.1281949515029985,
      "val_quality": 0.701214632341906,
      "patience_counter": 8
    },
    {
      "step": 11,
      "train_loss": 0.41756763313170364,
      "train_quality": 0.8938512617333497,
      "val_loss": 1.126149392602668,
      "val_quality": 0.7017563676752251,
      "patience_counter": 9
    },
    {
      "step": 12,
      "train_loss": 0.4156362479352857,
      "train_quality": 0.8943422339386643,
      "val_loss": 1.1237263501230585,
      "val_quality": 0.7023980738246427,
      "patience_counter": 10
    },
    {
      "step": 13,
      "train_loss": 0.41410175735819627,
      "train_quality": 0.8947323126366191,
      "val_loss": 1.1212873812263968,
      "val_quality": 0.7030439978447112,
      "patience_counter": 11
    },
    {
      "step": 14,
      "train_loss": 0.41284681055486444,
      "train_quality": 0.8950513292681678,
      "val_loss": 1.11887759040403,
      "val_quality": 0.7036821944931544,
      "patience_counter": 12
    },
    {
      "step": 15,
      "train_loss": 0.4117942123826426,
      "train_quality": 0.8953189074016672,
      "val_loss": 1.1164255027568861,
      "val_quality": 0.7043315928158519,
      "patience_counter": 13
    },
    {
      "step": 16,
      "train_loss": 0.4108902160129119,
      "train_quality": 0.8955487098730055,
      "val_loss": 1.1138738213601882,
      "val_quality": 0.7050073670366486,
      "patience_counter": 14
    },
    {
      "step": 17,
      "train_loss": 0.4100934358362371,
      "train_quality": 0.8957512572059863,
      "val_loss": 1.111237435448461,
      "val_quality": 0.7057055739669975,
      "patience_counter": 15
    },
    {
      "step": 18,
      "train_loss": 0.40937080534411757,
      "train_quality": 0.8959349551482721,
      "val_loss": 1.1086082236504347,
      "val_quality": 0.7064018809418495,
      "patience_counter": 16
    },
    {
      "step": 19,
      "train_loss": 0.40869962417174627,
      "train_quality": 0.8961055742981838,
      "val_loss": 1.106116704370392,
      "val_quality": 0.7070617221360713,
      "patience_counter": 17
    },
    {
      "step": 20,
      "train_loss": 0.40807133671148116,
      "train_quality": 0.8962652895535922,
      "val_loss": 1.103860217957363,
      "val_quality": 0.7076593184306073,
      "patience_counter": 18
    },
    {
      "step": 21,
      "train_loss": 0.4074887599492367,
      "train_quality": 0.8964133848161294,
      "val_loss": 1.101847109265134,
      "val_quality": 0.7081924598171575,
      "patience_counter": 19
    },
    {
      "step": 22,
      "train_loss": 0.4069568113947167,
      "train_quality": 0.8965486100189585,
      "val_loss": 1.1000179830371484,
      "val_quality": 0.7086768762309996,
      "patience_counter": 20
    }
  ],
  "summary": {
    "test_quality": 0.6051038061391235,
    "test_loss": 1.3342767932403061,
    "best_val_quality": 0.7183850323487755,
    "n_parameters": 4680
  }
}