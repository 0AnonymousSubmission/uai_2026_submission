{
  "experiment_name": "kfold_abalone",
  "run_name": "abalone-LMPO2-L3-d18-seed47659-fold4",
  "config": {
    "params": {
      "model": "LMPO2",
      "L": 3,
      "bond_dim": 18,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 4,
    "seed": 47659
  },
  "hparams": {
    "seed": 47659,
    "fold": 4,
    "dataset": "abalone",
    "n_features": 12,
    "n_train": 2841,
    "n_val": 501,
    "n_test": 835,
    "L": 3,
    "bond_dim": 18,
    "model": "LMPO2",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 4.574903611017887,
      "train_quality": 0.5672588677095372,
      "val_loss": 4.392329919298865,
      "val_quality": 0.5516124353236298,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 4.267880082793802,
      "train_quality": 0.5963002903361315,
      "val_loss": 4.054592175457632,
      "val_quality": 0.5860901287671214,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 4.201615016133161,
      "train_quality": 0.6025683174720406,
      "val_loss": 4.169045389518198,
      "val_quality": 0.5744062619208459,
      "patience_counter": 1
    },
    {
      "step": 4,
      "train_loss": 4.173210176810001,
      "train_quality": 0.6052551374307453,
      "val_loss": 4.227131748534292,
      "val_quality": 0.5684765613886278,
      "patience_counter": 2
    },
    {
      "step": 5,
      "train_loss": 4.1546499646884945,
      "train_quality": 0.6070107519511625,
      "val_loss": 4.25120600449425,
      "val_quality": 0.5660189597968501,
      "patience_counter": 3
    },
    {
      "step": 6,
      "train_loss": 4.147470890869207,
      "train_quality": 0.6076898221125258,
      "val_loss": 4.2733057225061515,
      "val_quality": 0.5637629273672615,
      "patience_counter": 4
    },
    {
      "step": 7,
      "train_loss": 4.143827659332436,
      "train_quality": 0.608034436179721,
      "val_loss": 4.274042765865259,
      "val_quality": 0.5636876868723708,
      "patience_counter": 5
    },
    {
      "step": 8,
      "train_loss": 4.141239178400195,
      "train_quality": 0.6082792811567457,
      "val_loss": 4.276149437388599,
      "val_quality": 0.5634726289574875,
      "patience_counter": 6
    },
    {
      "step": 9,
      "train_loss": 4.139728437539431,
      "train_quality": 0.6084221824648978,
      "val_loss": 4.275849925007368,
      "val_quality": 0.5635032044446842,
      "patience_counter": 7
    },
    {
      "step": 10,
      "train_loss": 4.138800781812003,
      "train_quality": 0.6085099296228698,
      "val_loss": 4.278357827273367,
      "val_quality": 0.5632471872032294,
      "patience_counter": 8
    },
    {
      "step": 11,
      "train_loss": 4.138072173928288,
      "train_quality": 0.6085788488018085,
      "val_loss": 4.281553658622648,
      "val_quality": 0.5629209432593207,
      "patience_counter": 9
    },
    {
      "step": 12,
      "train_loss": 4.137712338622953,
      "train_quality": 0.6086128857019726,
      "val_loss": 4.282046330706683,
      "val_quality": 0.562870649214929,
      "patience_counter": 10
    },
    {
      "step": 13,
      "train_loss": 4.137629913519933,
      "train_quality": 0.6086206823104792,
      "val_loss": 4.281382769950092,
      "val_quality": 0.5629383882958107,
      "patience_counter": 11
    },
    {
      "step": 14,
      "train_loss": 4.137707357492704,
      "train_quality": 0.6086133568681714,
      "val_loss": 4.280411091985206,
      "val_quality": 0.5630375812809302,
      "patience_counter": 12
    },
    {
      "step": 15,
      "train_loss": 4.137871303899042,
      "train_quality": 0.6085978491417698,
      "val_loss": 4.279399183198201,
      "val_quality": 0.563140881198062,
      "patience_counter": 13
    },
    {
      "step": 16,
      "train_loss": 4.1380786495808355,
      "train_quality": 0.6085782362684189,
      "val_loss": 4.278425095769502,
      "val_quality": 0.5632403201514106,
      "patience_counter": 14
    },
    {
      "step": 17,
      "train_loss": 4.138306747033637,
      "train_quality": 0.6085566604805137,
      "val_loss": 4.2775142079774175,
      "val_quality": 0.5633333074192821,
      "patience_counter": 15
    },
    {
      "step": 18,
      "train_loss": 4.138545899417649,
      "train_quality": 0.6085340390042495,
      "val_loss": 4.276686105873584,
      "val_quality": 0.5634178435749133,
      "patience_counter": 16
    },
    {
      "step": 19,
      "train_loss": 4.138793642272536,
      "train_quality": 0.6085106049534683,
      "val_loss": 4.27596163906603,
      "val_quality": 0.5634918002023745,
      "patience_counter": 17
    },
    {
      "step": 20,
      "train_loss": 4.139051359215398,
      "train_quality": 0.6084862274515257,
      "val_loss": 4.275351165625107,
      "val_quality": 0.5635541199061546,
      "patience_counter": 18
    },
    {
      "step": 21,
      "train_loss": 4.139322801812897,
      "train_quality": 0.6084605516369117,
      "val_loss": 4.274841991702979,
      "val_quality": 0.5636060985277823,
      "patience_counter": 19
    },
    {
      "step": 22,
      "train_loss": 4.139613328829297,
      "train_quality": 0.6084330706229434,
      "val_loss": 4.27439604232452,
      "val_quality": 0.563651622921316,
      "patience_counter": 20
    }
  ],
  "summary": {
    "test_quality": 0.579392032096768,
    "test_loss": 4.257890062646511,
    "best_val_quality": 0.5860901287671214,
    "n_parameters": 2376
  }
}