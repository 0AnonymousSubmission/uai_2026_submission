{
  "experiment_name": "kfold_appliances",
  "run_name": "appliances-LMPO2-L3-d8-seed19540-fold1",
  "config": {
    "params": {
      "model": "LMPO2",
      "L": 3,
      "bond_dim": 8,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 1,
    "seed": 19540
  },
  "hparams": {
    "seed": 19540,
    "fold": 1,
    "dataset": "appliances",
    "n_features": 28,
    "n_train": 13420,
    "n_val": 2368,
    "n_test": 3947,
    "L": 3,
    "bond_dim": 8,
    "model": "LMPO2",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 6146.481312063191,
      "train_quality": 0.4190204244542174,
      "val_loss": 7114.718816864976,
      "val_quality": 0.27874697279760186,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 5792.654668769806,
      "train_quality": 0.45246493402002896,
      "val_loss": 7064.714939384744,
      "val_quality": 0.28381610468219376,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 5594.170194962282,
      "train_quality": 0.4712261438066436,
      "val_loss": 7004.503374563627,
      "val_quality": 0.2899200385856504,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 5462.32396034137,
      "train_quality": 0.48368855368610275,
      "val_loss": 6916.483918512683,
      "val_quality": 0.2988429912368453,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 5366.405845315678,
      "train_quality": 0.49275495492048194,
      "val_loss": 6838.385660254669,
      "val_quality": 0.3067601846829594,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 5289.983400234295,
      "train_quality": 0.4999785805123165,
      "val_loss": 6781.9138765592525,
      "val_quality": 0.31248499911206784,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 5226.288815940763,
      "train_quality": 0.5059991393765879,
      "val_loss": 6742.998264633375,
      "val_quality": 0.3164300605585497,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 5171.556849469411,
      "train_quality": 0.5111725309537989,
      "val_loss": 6715.453424668808,
      "val_quality": 0.3192224125431645,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 5123.703664055911,
      "train_quality": 0.5156957242962215,
      "val_loss": 6694.927444737825,
      "val_quality": 0.32130322916327103,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 5081.792297770788,
      "train_quality": 0.5196572832042565,
      "val_loss": 6679.183858770718,
      "val_quality": 0.32289923166598145,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 5045.068489071582,
      "train_quality": 0.5231285022167693,
      "val_loss": 6666.786595913146,
      "val_quality": 0.3241560014126441,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 5012.762824173905,
      "train_quality": 0.5261821080974447,
      "val_loss": 6656.822221967237,
      "val_quality": 0.3251661375905669,
      "patience_counter": 0
    },
    {
      "step": 13,
      "train_loss": 4984.176680054636,
      "train_quality": 0.5288841363041048,
      "val_loss": 6648.887512512269,
      "val_quality": 0.3259705169851259,
      "patience_counter": 0
    },
    {
      "step": 14,
      "train_loss": 4958.718351645499,
      "train_quality": 0.5312905161631334,
      "val_loss": 6642.771613101138,
      "val_quality": 0.3265905149186896,
      "patience_counter": 0
    },
    {
      "step": 15,
      "train_loss": 4935.891391755674,
      "train_quality": 0.5334481730068569,
      "val_loss": 6638.182799092853,
      "val_quality": 0.3270557049114269,
      "patience_counter": 0
    },
    {
      "step": 16,
      "train_loss": 4915.274888956107,
      "train_quality": 0.535396892353359,
      "val_loss": 6634.701982487562,
      "val_quality": 0.3274085719154961,
      "patience_counter": 0
    },
    {
      "step": 17,
      "train_loss": 4896.513409698596,
      "train_quality": 0.5371702706005599,
      "val_loss": 6631.867026248093,
      "val_quality": 0.32769596496957676,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 4879.315415552423,
      "train_quality": 0.5387958646326563,
      "val_loss": 6629.267691469059,
      "val_quality": 0.32795947195085706,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 4863.451290616701,
      "train_quality": 0.5402953782736515,
      "val_loss": 6626.600333186359,
      "val_quality": 0.3282298747995923,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 4848.746184377089,
      "train_quality": 0.5416853387970291,
      "val_loss": 6623.684905137023,
      "val_quality": 0.3285254256653821,
      "patience_counter": 0
    },
    {
      "step": 21,
      "train_loss": 4835.06862368456,
      "train_quality": 0.5429781733477583,
      "val_loss": 6620.4537557526855,
      "val_quality": 0.3288529827108231,
      "patience_counter": 0
    },
    {
      "step": 22,
      "train_loss": 4822.318080720211,
      "train_quality": 0.5441833840469052,
      "val_loss": 6616.924752215406,
      "val_quality": 0.3292107346543346,
      "patience_counter": 0
    },
    {
      "step": 23,
      "train_loss": 4810.414231062971,
      "train_quality": 0.5453085633438228,
      "val_loss": 6613.169166351654,
      "val_quality": 0.3295914563304644,
      "patience_counter": 0
    },
    {
      "step": 24,
      "train_loss": 4799.288892616618,
      "train_quality": 0.5463601559673423,
      "val_loss": 6609.282361270161,
      "val_quality": 0.3299854803254151,
      "patience_counter": 0
    },
    {
      "step": 25,
      "train_loss": 4788.88088186918,
      "train_quality": 0.5473439451239863,
      "val_loss": 6605.36187998972,
      "val_quality": 0.33038291823749477,
      "patience_counter": 0
    },
    {
      "step": 26,
      "train_loss": 4779.133187903326,
      "train_quality": 0.5482653196170181,
      "val_loss": 6601.494304947142,
      "val_quality": 0.33077499279155576,
      "patience_counter": 0
    },
    {
      "step": 27,
      "train_loss": 4769.991748562503,
      "train_quality": 0.5491293895260383,
      "val_loss": 6597.74862671244,
      "val_quality": 0.331154710084009,
      "patience_counter": 0
    },
    {
      "step": 28,
      "train_loss": 4761.405057131472,
      "train_quality": 0.5499410233844464,
      "val_loss": 6594.174774558933,
      "val_quality": 0.3315170085459497,
      "patience_counter": 0
    },
    {
      "step": 29,
      "train_loss": 4753.32417250605,
      "train_quality": 0.5507048472181735,
      "val_loss": 6590.805176074448,
      "val_quality": 0.33185860083792185,
      "patience_counter": 0
    },
    {
      "step": 30,
      "train_loss": 4745.702677313106,
      "train_quality": 0.5514252485042769,
      "val_loss": 6587.657732766237,
      "val_quality": 0.33217767219863603,
      "patience_counter": 0
    },
    {
      "step": 31,
      "train_loss": 4738.497479209802,
      "train_quality": 0.5521063004302894,
      "val_loss": 6584.74223664146,
      "val_quality": 0.33247322996555817,
      "patience_counter": 0
    },
    {
      "step": 32,
      "train_loss": 4731.667674175837,
      "train_quality": 0.5527518693384558,
      "val_loss": 6582.060717352757,
      "val_quality": 0.3327450683831067,
      "patience_counter": 0
    },
    {
      "step": 33,
      "train_loss": 4725.175269413229,
      "train_quality": 0.5533655463955792,
      "val_loss": 6579.614163100309,
      "val_quality": 0.33299308727270915,
      "patience_counter": 0
    },
    {
      "step": 34,
      "train_loss": 4718.984792652987,
      "train_quality": 0.5539506845222555,
      "val_loss": 6577.404391056399,
      "val_quality": 0.33321710241893243,
      "patience_counter": 0
    },
    {
      "step": 35,
      "train_loss": 4713.063125691665,
      "train_quality": 0.5545104141273811,
      "val_loss": 6575.436076383822,
      "val_quality": 0.3334166398781947,
      "patience_counter": 0
    },
    {
      "step": 36,
      "train_loss": 4707.3793155239855,
      "train_quality": 0.5550476609603325,
      "val_loss": 6573.717637507483,
      "val_quality": 0.33359084623455604,
      "patience_counter": 0
    },
    {
      "step": 37,
      "train_loss": 4701.904399073898,
      "train_quality": 0.5555651626777911,
      "val_loss": 6572.261414074019,
      "val_quality": 0.33373847055910144,
      "patience_counter": 0
    },
    {
      "step": 38,
      "train_loss": 4696.611281883974,
      "train_quality": 0.5560654803103008,
      "val_loss": 6571.083123247784,
      "val_quality": 0.33385791952781285,
      "patience_counter": 0
    },
    {
      "step": 39,
      "train_loss": 4691.4746247987,
      "train_quality": 0.5565510089732237,
      "val_loss": 6570.20120241879,
      "val_quality": 0.33394732405440597,
      "patience_counter": 1
    },
    {
      "step": 40,
      "train_loss": 4686.4708311843815,
      "train_quality": 0.5570239790747451,
      "val_loss": 6569.63562022833,
      "val_quality": 0.3340046598223402,
      "patience_counter": 0
    },
    {
      "step": 41,
      "train_loss": 4681.5780239210635,
      "train_quality": 0.5574864584906494,
      "val_loss": 6569.406922502732,
      "val_quality": 0.3340278440030714,
      "patience_counter": 1
    },
    {
      "step": 42,
      "train_loss": 4676.776108200581,
      "train_quality": 0.5579403466285042,
      "val_loss": 6569.535210085095,
      "val_quality": 0.33401483887813066,
      "patience_counter": 2
    },
    {
      "step": 43,
      "train_loss": 4672.046837051388,
      "train_quality": 0.5583873682341027,
      "val_loss": 6570.039118060848,
      "val_quality": 0.3339637553199045,
      "patience_counter": 3
    },
    {
      "step": 44,
      "train_loss": 4667.373892856041,
      "train_quality": 0.5588290656862422,
      "val_loss": 6570.935026162502,
      "val_quality": 0.33387293283667696,
      "patience_counter": 4
    },
    {
      "step": 45,
      "train_loss": 4662.743015283124,
      "train_quality": 0.5592667869043053,
      "val_loss": 6572.236349748459,
      "val_quality": 0.33374101144949353,
      "patience_counter": 5
    },
    {
      "step": 46,
      "train_loss": 4658.1420726348815,
      "train_quality": 0.5597016786043159,
      "val_loss": 6573.952962669988,
      "val_quality": 0.33356699019889224,
      "patience_counter": 6
    },
    {
      "step": 47,
      "train_loss": 4653.561160876582,
      "train_quality": 0.5601346769384564,
      "val_loss": 6576.090639596543,
      "val_quality": 0.33335028367905006,
      "patience_counter": 7
    },
    {
      "step": 48,
      "train_loss": 4648.992658612792,
      "train_quality": 0.5605665022985835,
      "val_loss": 6578.650896525541,
      "val_quality": 0.33309073820606827,
      "patience_counter": 8
    },
    {
      "step": 49,
      "train_loss": 4644.431250884689,
      "train_quality": 0.5609976570668513,
      "val_loss": 6581.6305721696335,
      "val_quality": 0.3327886742547441,
      "patience_counter": 9
    },
    {
      "step": 50,
      "train_loss": 4639.873873324873,
      "train_quality": 0.5614284308943267,
      "val_loss": 6585.021785290896,
      "val_quality": 0.33244489078380746,
      "patience_counter": 10
    }
  ],
  "summary": {
    "test_quality": 0.330750841566673,
    "test_loss": 7134.571466857982,
    "best_val_quality": 0.3340046598223402,
    "n_parameters": 2296
  }
}