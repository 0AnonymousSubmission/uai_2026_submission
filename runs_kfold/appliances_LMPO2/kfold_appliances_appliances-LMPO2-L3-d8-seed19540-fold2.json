{
  "experiment_name": "kfold_appliances",
  "run_name": "appliances-LMPO2-L3-d8-seed19540-fold2",
  "config": {
    "params": {
      "model": "LMPO2",
      "L": 3,
      "bond_dim": 8,
      "init_strength": 0.1,
      "bond_prior_alpha": 5.0,
      "added_bias": true,
      "n_epochs": 50,
      "batch_size": 256,
      "patience": 20,
      "min_delta": 0.0001,
      "warmup_epochs": 5,
      "decay": 1.0
    },
    "fold": 2,
    "seed": 19540
  },
  "hparams": {
    "seed": 19540,
    "fold": 2,
    "dataset": "appliances",
    "n_features": 28,
    "n_train": 13420,
    "n_val": 2368,
    "n_test": 3947,
    "L": 3,
    "bond_dim": 8,
    "model": "LMPO2",
    "init_strength": 0.1,
    "bond_prior_alpha": 5.0,
    "added_bias": true,
    "n_epochs": 50,
    "batch_size": 256,
    "patience": 20,
    "min_delta": 0.0001,
    "warmup_epochs": 5,
    "decay": 1.0
  },
  "metrics_log": [
    {
      "step": 1,
      "train_loss": 6274.007294986986,
      "train_quality": 0.3961938151292598,
      "val_loss": 7015.308979843712,
      "val_quality": 0.314859444087742,
      "patience_counter": 0
    },
    {
      "step": 2,
      "train_loss": 5879.199854609501,
      "train_quality": 0.43418981403786583,
      "val_loss": 6813.773593221904,
      "val_quality": 0.3345421219602045,
      "patience_counter": 0
    },
    {
      "step": 3,
      "train_loss": 5686.113869935517,
      "train_quality": 0.4527722775697719,
      "val_loss": 6708.1987992622735,
      "val_quality": 0.3448529398060971,
      "patience_counter": 0
    },
    {
      "step": 4,
      "train_loss": 5553.688196014554,
      "train_quality": 0.4655168341489525,
      "val_loss": 6628.582290998316,
      "val_quality": 0.3526285771855039,
      "patience_counter": 0
    },
    {
      "step": 5,
      "train_loss": 5454.470722600371,
      "train_quality": 0.4750654561504919,
      "val_loss": 6568.950529429219,
      "val_quality": 0.35845243161427753,
      "patience_counter": 0
    },
    {
      "step": 6,
      "train_loss": 5368.248901410304,
      "train_quality": 0.48336338544154955,
      "val_loss": 6525.3536358129695,
      "val_quality": 0.3627102625970764,
      "patience_counter": 0
    },
    {
      "step": 7,
      "train_loss": 5290.74233116865,
      "train_quality": 0.4908225649228075,
      "val_loss": 6493.498961604831,
      "val_quality": 0.3658213057824977,
      "patience_counter": 0
    },
    {
      "step": 8,
      "train_loss": 5222.881228069556,
      "train_quality": 0.4973534712219001,
      "val_loss": 6471.088610490504,
      "val_quality": 0.368009982070994,
      "patience_counter": 0
    },
    {
      "step": 9,
      "train_loss": 5165.234546742307,
      "train_quality": 0.5029013485331804,
      "val_loss": 6454.037000809217,
      "val_quality": 0.3696753042071682,
      "patience_counter": 0
    },
    {
      "step": 10,
      "train_loss": 5117.088936343323,
      "train_quality": 0.5075348492555195,
      "val_loss": 6438.662684153072,
      "val_quality": 0.37117681581425865,
      "patience_counter": 0
    },
    {
      "step": 11,
      "train_loss": 5076.9378935842915,
      "train_quality": 0.5113989582383516,
      "val_loss": 6423.582086793876,
      "val_quality": 0.3726496417279648,
      "patience_counter": 0
    },
    {
      "step": 12,
      "train_loss": 5043.08133371407,
      "train_quality": 0.5146572904791222,
      "val_loss": 6408.990510214827,
      "val_quality": 0.3740747080960649,
      "patience_counter": 0
    },
    {
      "step": 13,
      "train_loss": 5014.001340016547,
      "train_quality": 0.5174559292477758,
      "val_loss": 6395.5270556294945,
      "val_quality": 0.3753895979727043,
      "patience_counter": 0
    },
    {
      "step": 14,
      "train_loss": 4988.515159857554,
      "train_quality": 0.5199087018515034,
      "val_loss": 6383.63445285117,
      "val_quality": 0.3765510727562379,
      "patience_counter": 0
    },
    {
      "step": 15,
      "train_loss": 4965.772223374541,
      "train_quality": 0.5220974665540146,
      "val_loss": 6373.356104017323,
      "val_quality": 0.3775548936362755,
      "patience_counter": 0
    },
    {
      "step": 16,
      "train_loss": 4945.181284672427,
      "train_quality": 0.5240791244571804,
      "val_loss": 6364.4063603402465,
      "val_quality": 0.37842895811095534,
      "patience_counter": 0
    },
    {
      "step": 17,
      "train_loss": 4926.321730615561,
      "train_quality": 0.5258941550824298,
      "val_loss": 6356.343279957281,
      "val_quality": 0.3792164278278022,
      "patience_counter": 0
    },
    {
      "step": 18,
      "train_loss": 4908.871024188882,
      "train_quality": 0.5275735991722081,
      "val_loss": 6348.74006759584,
      "val_quality": 0.3799589851633385,
      "patience_counter": 0
    },
    {
      "step": 19,
      "train_loss": 4892.56270178313,
      "train_quality": 0.5291431010026136,
      "val_loss": 6341.297003924674,
      "val_quality": 0.38068590179609185,
      "patience_counter": 0
    },
    {
      "step": 20,
      "train_loss": 4877.1729603725025,
      "train_quality": 0.5306241992242753,
      "val_loss": 6333.861343074769,
      "val_quality": 0.3814120954424325,
      "patience_counter": 0
    },
    {
      "step": 21,
      "train_loss": 4862.520917833357,
      "train_quality": 0.5320343018094595,
      "val_loss": 6326.3887898728135,
      "val_quality": 0.3821418921298745,
      "patience_counter": 0
    },
    {
      "step": 22,
      "train_loss": 4848.4690719664295,
      "train_quality": 0.5333866418760833,
      "val_loss": 6318.904704270739,
      "val_quality": 0.3828728151134,
      "patience_counter": 0
    },
    {
      "step": 23,
      "train_loss": 4834.920518852443,
      "train_quality": 0.5346905453912755,
      "val_loss": 6311.486286647806,
      "val_quality": 0.3835973247235638,
      "patience_counter": 0
    },
    {
      "step": 24,
      "train_loss": 4821.814037449148,
      "train_quality": 0.5359519042264057,
      "val_loss": 6304.253796088821,
      "val_quality": 0.38430367602133986,
      "patience_counter": 0
    },
    {
      "step": 25,
      "train_loss": 4809.117465011704,
      "train_quality": 0.5371738137021109,
      "val_loss": 6297.35739306242,
      "val_quality": 0.3849772037899498,
      "patience_counter": 0
    },
    {
      "step": 26,
      "train_loss": 4796.819798051309,
      "train_quality": 0.538357332786652,
      "val_loss": 6290.954387753456,
      "val_quality": 0.38560254454536014,
      "patience_counter": 0
    },
    {
      "step": 27,
      "train_loss": 4784.923246450283,
      "train_quality": 0.539502248802461,
      "val_loss": 6285.181901218293,
      "val_quality": 0.3861663065471568,
      "patience_counter": 0
    },
    {
      "step": 28,
      "train_loss": 4773.436275310549,
      "train_quality": 0.5406077470738999,
      "val_loss": 6280.133537254928,
      "val_quality": 0.38665934810844005,
      "patience_counter": 0
    },
    {
      "step": 29,
      "train_loss": 4762.368383810519,
      "train_quality": 0.5416729134065141,
      "val_loss": 6275.846739014401,
      "val_quality": 0.3870780123950791,
      "patience_counter": 0
    },
    {
      "step": 30,
      "train_loss": 4751.726502850057,
      "train_quality": 0.5426970807752258,
      "val_loss": 6272.303435331594,
      "val_quality": 0.38742406430269705,
      "patience_counter": 0
    },
    {
      "step": 31,
      "train_loss": 4741.512732888441,
      "train_quality": 0.5436800470332661,
      "val_loss": 6269.4412869707485,
      "val_quality": 0.3877035921074862,
      "patience_counter": 0
    },
    {
      "step": 32,
      "train_loss": 4731.72324368623,
      "train_quality": 0.5446221808002676,
      "val_loss": 6267.169913214412,
      "val_quality": 0.38792542271859276,
      "patience_counter": 0
    },
    {
      "step": 33,
      "train_loss": 4722.348088441792,
      "train_quality": 0.545524439349638,
      "val_loss": 6265.387713738696,
      "val_quality": 0.3880994787926798,
      "patience_counter": 0
    },
    {
      "step": 34,
      "train_loss": 4713.371782244795,
      "train_quality": 0.5463883129385915,
      "val_loss": 6263.99552512734,
      "val_quality": 0.3882354449891594,
      "patience_counter": 0
    },
    {
      "step": 35,
      "train_loss": 4704.774427291636,
      "train_quality": 0.5472157165181815,
      "val_loss": 6262.905361524177,
      "val_quality": 0.3883419143263266,
      "patience_counter": 0
    },
    {
      "step": 36,
      "train_loss": 4696.533128972513,
      "train_quality": 0.5480088534500477,
      "val_loss": 6262.0448774793085,
      "val_quality": 0.3884259523235907,
      "patience_counter": 1
    },
    {
      "step": 37,
      "train_loss": 4688.623486370362,
      "train_quality": 0.5487700720618129,
      "val_loss": 6261.3581314878475,
      "val_quality": 0.3884930224315092,
      "patience_counter": 0
    },
    {
      "step": 38,
      "train_loss": 4681.02097594682,
      "train_quality": 0.5495017324820912,
      "val_loss": 6260.804634503739,
      "val_quality": 0.38854707895738394,
      "patience_counter": 1
    },
    {
      "step": 39,
      "train_loss": 4673.702112312355,
      "train_quality": 0.5502060949287602,
      "val_loss": 6260.357049369062,
      "val_quality": 0.388590791747351,
      "patience_counter": 2
    },
    {
      "step": 40,
      "train_loss": 4666.6453548222535,
      "train_quality": 0.550885232458782,
      "val_loss": 6259.998506616038,
      "val_quality": 0.388625808334907,
      "patience_counter": 0
    },
    {
      "step": 41,
      "train_loss": 4659.831657446082,
      "train_quality": 0.5515409780491413,
      "val_loss": 6259.720406129054,
      "val_quality": 0.3886529686385799,
      "patience_counter": 1
    },
    {
      "step": 42,
      "train_loss": 4653.244770495318,
      "train_quality": 0.5521748955587835,
      "val_loss": 6259.5203363463625,
      "val_quality": 0.38867250818024923,
      "patience_counter": 2
    },
    {
      "step": 43,
      "train_loss": 4646.8712591821295,
      "train_quality": 0.5527882779425308,
      "val_loss": 6259.400200429592,
      "val_quality": 0.3886842410902377,
      "patience_counter": 3
    },
    {
      "step": 44,
      "train_loss": 4640.700303508877,
      "train_quality": 0.5533821665095795,
      "val_loss": 6259.365245259995,
      "val_quality": 0.3886876549390642,
      "patience_counter": 4
    },
    {
      "step": 45,
      "train_loss": 4634.723331992114,
      "train_quality": 0.5539573861736531,
      "val_loss": 6259.423177031187,
      "val_quality": 0.38868199711187046,
      "patience_counter": 5
    },
    {
      "step": 46,
      "train_loss": 4628.933540158019,
      "train_quality": 0.5545145917926733,
      "val_loss": 6259.58328629363,
      "val_quality": 0.38866636025975276,
      "patience_counter": 6
    },
    {
      "step": 47,
      "train_loss": 4623.325366738966,
      "train_quality": 0.5550543185792451,
      "val_loss": 6259.8558799307475,
      "val_quality": 0.3886397377750399,
      "patience_counter": 7
    },
    {
      "step": 48,
      "train_loss": 4617.893946758985,
      "train_quality": 0.5555770347353395,
      "val_loss": 6260.25153329937,
      "val_quality": 0.3886010968299718,
      "patience_counter": 8
    },
    {
      "step": 49,
      "train_loss": 4612.634614278027,
      "train_quality": 0.5560831893078457,
      "val_loss": 6260.780578216338,
      "val_quality": 0.3885494283817885,
      "patience_counter": 9
    },
    {
      "step": 50,
      "train_loss": 4607.542469227994,
      "train_quality": 0.5565732538759767,
      "val_loss": 6261.452071427185,
      "val_quality": 0.3884838479158258,
      "patience_counter": 10
    }
  ],
  "summary": {
    "test_quality": 0.3685829747890357,
    "test_loss": 6997.255859298954,
    "best_val_quality": 0.388625808334907,
    "n_parameters": 2296
  }
}